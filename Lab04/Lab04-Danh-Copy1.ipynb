{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extending Logistic Regression: 2015 American Community Survey\n",
    "\n",
    "## Conrad Appel, Erik Gabrielsen, Danh Nguyen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation and Overview (30 points total)\n",
    "\n",
    "[5 points] Explain the task and what business-case or use-case it is designed to solve (or designed to investigate). Detail exactly what the classification task is and what parties would be interested in the results.\n",
    "\n",
    "[10 points] (mostly the same processes as from lab one) Define and prepare your class variables. Use proper variable representations (int, float, one-hot, etc.). Use pre-processing methods (as needed) for dimensionality reduction, scaling, etc. Remove variables that are not needed/useful for the analysis. Describe the final dataset that is used for classification/regression (include a description of any newly formed variables you created).\n",
    "\n",
    "[15 points] Divide you data into training and testing data using an 80% training and 20% testing split. Use the cross validation modules that are part of scikit-learn. Argue for or against splitting your data using an 80/20 split. That is, why is the 80/20 split appropriate (or not) for your dataset?  \n",
    "\n",
    "### Modeling (50 points total)\n",
    "\n",
    "[20 points] Create a custom, one-versus-all logistic regression classifier using numpy and scipy to optimize. Use object oriented conventions identical to scikit-learn. You should start with the template used in the course. You should add the following functionality to the logistic regression classifier:\n",
    "Ability to choose optimization technique when class is instantiated: either steepest descent, stochastic gradient descent, or Newton's method. Update the gradient calculation to include a customizable regularization term (either using no regularization, L1 regularization, L2 regularization, or both L1/L2 norm of the weights). Associate a cost with the regularization term, \"C\", that can be adjusted when the class is instantiated.  \n",
    "\n",
    "[15 points] Train your classifier to achieve good generalization performance. That is, adjust the optimization technique and the value of the regularization term \"C\" to achieve the best performance on your test set. Is your method of selecting parameters justified? That is, do you think there is any \"data snooping\" involved with this method of selecting parameters?\n",
    "\n",
    "[15 points] Compare the performance of your \"best\" logistic regression optimization procedure to the procedure used in scikit-learn. Visualize the performance differences in terms of training time, training iterations, and memory usage while training. Discuss the results. \n",
    "\n",
    "### Deployment (10 points total)\n",
    "\n",
    "Which implementation of logistic regression would you advise be used in a deployed machine learning model, your implementation or scikit-learn (or other third party)? Why?\n",
    "\n",
    "### Exceptional Work (10 points total)\n",
    "\n",
    "You have free reign to provide additional analyses.\n",
    "One idea: Make your implementation of logistic regression compatible with the GridSearchCV function that is part of scikit-learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Overview\n",
    "\n",
    "In this lab, we are investigating the relationship between individual income and ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Attribute**|**Description**|**Example**\n",
    ":-----:|:-----:|:-----:\n",
    "AGEP|Age| \n",
    "PINCP|Total person's income (signed)| \n",
    "QTRBIR|Quarter of birth|1 - January through March, 2 -  April through June, etc.\n",
    "JWAP|Time of arrival at work | \n",
    "JWDP|Time of departure for work| \n",
    "YOEP|Year of entry to the US| \n",
    "WAOB|World area of birth| \n",
    "RAC1P|Recoded detailed race code|1 - White alone, 2 - Black or African American alone, etc.\n",
    "MAR|Marital status|1 - Married, 2 - Widowed\n",
    "MIL|Military Service |1 - Now on active duty, 4 - Never served in the military\n",
    "SCHL|Educational attainment|23 - Professional degree, 24 - Doctorate degree, etc.\n",
    "FOD1P|Recoded field of degree|1904 - advertising, 2001 - communication technologies, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 3s, sys: 17 s, total: 1min 20s\n",
      "Wall time: 1min 44s\n"
     ]
    }
   ],
   "source": [
    "## redoing large files\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "%time df = pd.read_csv('~/Downloads/ss15pusb.csv') # read in the csv file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.head(10)\n",
    "df.shape\n",
    "\n",
    "new_df = df.filter(items=['AGEP','PINCP', 'MAR', 'MIL', 'SCHL','QTRBIR','JWAP','JWDP','YOEP','WAOB','RAC1P', 'FOD1P'])\n",
    "new_df.shape\n",
    "new_df.to_csv('~/Downloads/ss15pusb3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.85 s, sys: 340 ms, total: 2.19 s\n",
      "Wall time: 2.54 s\n"
     ]
    }
   ],
   "source": [
    "%time new_df = pd.read_csv('~/Downloads/ss15pusb3.csv') # read in the csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['JWAP', 'JWDP', 'YOEP', 'FOD1P']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# delete younger than 18\n",
    "new_df = new_df[new_df.AGEP >= 18]\n",
    "\n",
    "# find null columns\n",
    "new_df.columns[new_df.isnull().any()].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#new_df[new_df['JWAP'].isnull()]\n",
    "# clean out JWAP and JWDP. They are ordinal variables, create a new one to classify them\n",
    "\n",
    "df_grouped = new_df.groupby(by=['JWAP', 'JWDP'])\n",
    "# new_df = new_df.groupby(by=['JWAP', 'JWDP']).transform('median')\n",
    "\n",
    "# fill null values \n",
    "new_df['JWAP'].fillna(0, inplace=True)\n",
    "new_df['JWDP'].fillna(0, inplace=True)\n",
    "new_df['FOD1P'].fillna(0, inplace=True)\n",
    "\n",
    "## fill null values in YOEP (Year of entrance into US)\n",
    "new_df['YOEP'].fillna(0, inplace=True)\n",
    "\n",
    "new_df.columns[new_df.isnull().any()].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['AGEP', 'PINCP', 'MAR', 'MIL', 'SCHL', 'QTRBIR', 'JWAP', 'JWDP', 'YOEP',\n",
       "       'WAOB', 'RAC1P', 'FOD1P'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PINCP</th>\n",
       "      <th>MAR</th>\n",
       "      <th>MIL</th>\n",
       "      <th>SCHL</th>\n",
       "      <th>QTRBIR</th>\n",
       "      <th>JWAP</th>\n",
       "      <th>JWDP</th>\n",
       "      <th>YOEP</th>\n",
       "      <th>WAOB</th>\n",
       "      <th>RAC1P</th>\n",
       "      <th>FOD1P</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9100.0</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5404.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25300.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2</td>\n",
       "      <td>82.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3600.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PINCP  MAR  MIL  SCHL  QTRBIR  JWAP  JWDP  YOEP  WAOB  RAC1P   FOD1P\n",
       "0   9100.0    3  4.0  16.0       1   0.0   0.0   0.0     1      1     0.0\n",
       "1   5000.0    1  4.0  11.0       2   0.0   0.0   0.0     1      1     0.0\n",
       "2  20000.0    1  4.0  22.0       4   0.0   0.0   0.0     1      1  5404.0\n",
       "3  11000.0    1  4.0  16.0       2   0.0   0.0   0.0     1      1     0.0\n",
       "4  25300.0    1  4.0  21.0       2  82.0  34.0   0.0     1      1  3600.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df[pd.isnull(new_df).any(axis=1)]\n",
    "new_df.dropna(inplace=True)\n",
    "new_df.drop(new_df.columns[0], axis=1, inplace=True)\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PINCP</th>\n",
       "      <th>MAR</th>\n",
       "      <th>MIL</th>\n",
       "      <th>SCHL</th>\n",
       "      <th>QTRBIR</th>\n",
       "      <th>JWAP</th>\n",
       "      <th>JWDP</th>\n",
       "      <th>YOEP</th>\n",
       "      <th>WAOB</th>\n",
       "      <th>RAC1P</th>\n",
       "      <th>FOD1P</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9100.0</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5404.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25300.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2</td>\n",
       "      <td>82.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3600.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PINCP  MAR  MIL  SCHL  QTRBIR  JWAP  JWDP  YOEP  WAOB  RAC1P   FOD1P\n",
       "0   9100.0    3  4.0  16.0       1   0.0   0.0   0.0     1      1     0.0\n",
       "1   5000.0    1  4.0  11.0       2   0.0   0.0   0.0     1      1     0.0\n",
       "2  20000.0    1  4.0  22.0       4   0.0   0.0   0.0     1      1  5404.0\n",
       "3  11000.0    1  4.0  16.0       2   0.0   0.0   0.0     1      1     0.0\n",
       "4  25300.0    1  4.0  21.0       2  82.0  34.0   0.0     1      1  3600.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_df['PINCP'] = pd.cut(new_df.PINCP,[0,20000,60000,100000,150000,1e8],5,labels=[0,1,2,3,4]) # this creates a new variable\n",
    "# 4. drop rows that still had missing values after grouped imputation\n",
    "new_df.dropna(inplace=True)\n",
    "new_df['PINCP'] = new_df['PINCP'].astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "414846\n",
      "449991\n",
      "48030\n",
      "136700\n",
      "37839\n"
     ]
    }
   ],
   "source": [
    "for value in new_df.PINCP.unique(): \n",
    "    print(len(new_df[new_df['PINCP'] == value]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1087406 entries, 0 to 1528515\n",
      "Data columns (total 11 columns):\n",
      "PINCP     1087406 non-null int64\n",
      "MAR       1087406 non-null int64\n",
      "MIL       1087406 non-null float64\n",
      "SCHL      1087406 non-null float64\n",
      "QTRBIR    1087406 non-null int64\n",
      "JWAP      1087406 non-null float64\n",
      "JWDP      1087406 non-null float64\n",
      "YOEP      1087406 non-null float64\n",
      "WAOB      1087406 non-null int64\n",
      "RAC1P     1087406 non-null int64\n",
      "FOD1P     1087406 non-null float64\n",
      "dtypes: float64(6), int64(5)\n",
      "memory usage: 99.6 MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PINCP</th>\n",
       "      <th>MAR</th>\n",
       "      <th>MIL</th>\n",
       "      <th>SCHL</th>\n",
       "      <th>QTRBIR</th>\n",
       "      <th>JWAP</th>\n",
       "      <th>JWDP</th>\n",
       "      <th>YOEP</th>\n",
       "      <th>WAOB</th>\n",
       "      <th>RAC1P</th>\n",
       "      <th>FOD1P</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5404.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2</td>\n",
       "      <td>82.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3600.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PINCP  MAR  MIL  SCHL  QTRBIR  JWAP  JWDP  YOEP  WAOB  RAC1P   FOD1P\n",
       "0      0    3  4.0  16.0       1   0.0   0.0   0.0     1      1     0.0\n",
       "1      0    1  4.0  11.0       2   0.0   0.0   0.0     1      1     0.0\n",
       "2      0    1  4.0  22.0       4   0.0   0.0   0.0     1      1  5404.0\n",
       "3      0    1  4.0  16.0       2   0.0   0.0   0.0     1      1     0.0\n",
       "4      1    1  4.0  21.0       2  82.0  34.0   0.0     1      1  3600.0"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.info()\n",
    "new_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ShuffleSplit(1087406, n_iter=1, test_size=0.2, random_state=None)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import ShuffleSplit\n",
    "df_imputed = new_df.copy()\n",
    "# we want to predict the X and y data as follows:\n",
    "if 'PINCP' in new_df:\n",
    "    y = df_imputed['PINCP'].values # get the labels we want\n",
    "    del df_imputed['PINCP'] # get rid of the class label\n",
    "    X = df_imputed.values # use everything else to predict!\n",
    "\n",
    "    ## X and y are now numpy matrices, by calling 'values' on the pandas data frames we\n",
    "    #    have converted them into simple matrices to use with scikit learn\n",
    "    \n",
    "    \n",
    "# to use the cross validation object in scikit learn, we need to grab an instance\n",
    "#    of the object and set it up. This object will be able to split our data into \n",
    "#    training and testing splits\n",
    "num_cv_iterations = 1\n",
    "num_instances = len(y)\n",
    "cv_object = ShuffleSplit(n=num_instances,\n",
    "                         n_iter=num_cv_iterations,\n",
    "                         test_size  = 0.2)\n",
    "                         \n",
    "print(cv_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Iteration 0  ====\n",
      "accuracy 0.544886473363\n",
      "confusion matrix\n",
      " [[58392 24442     1     0     0]\n",
      " [29942 60094     6     0     1]\n",
      " [ 4112 23359    17     0     0]\n",
      " [ 1102  8452    11     0     1]\n",
      " [  876  6661    13     0     0]]\n"
     ]
    }
   ],
   "source": [
    "# run logistic regression and vary some parameters\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics as mt\n",
    "\n",
    "# first we create a reusable logisitic regression object\n",
    "#   here we can setup the object with different learning parameters and constants\n",
    "lr_clf = LogisticRegression(penalty='l2', C=1.0, class_weight=None) # get object\n",
    "\n",
    "# now we can use the cv_object that we setup before to iterate through the \n",
    "#    different training and testing sets. Each time we will reuse the logisitic regression \n",
    "#    object, but it gets trained on different data each time we use it.\n",
    "\n",
    "iter_num=0\n",
    "# the indices are the rows used for training and testing in each iteration\n",
    "for train_indices, test_indices in cv_object: \n",
    "    # I will create new variables here so that it is more obvious what \n",
    "    # the code is doing (you can compact this syntax and avoid duplicating memory,\n",
    "    # but it makes this code less readable)\n",
    "    X_train = X[train_indices]\n",
    "    y_train = y[train_indices]\n",
    "    \n",
    "    X_test = X[test_indices]\n",
    "    y_test = y[test_indices]\n",
    "    \n",
    "    # train the reusable logisitc regression model on the training data\n",
    "    lr_clf.fit(X_train,y_train)  # train object\n",
    "    y_hat = lr_clf.predict(X_test) # get test set precitions\n",
    "\n",
    "    # now let's get the accuracy and confusion matrix for this iterations of training/testing\n",
    "    acc = mt.accuracy_score(y_test,y_hat)\n",
    "    conf = mt.confusion_matrix(y_test,y_hat)\n",
    "    print(\"====Iteration\",iter_num,\" ====\")\n",
    "    print(\"accuracy\", acc )\n",
    "    print(\"confusion matrix\\n\",conf)\n",
    "    iter_num+=1\n",
    "    \n",
    "# Also note that every time you run the above code\n",
    "#   it randomly creates a new training and testing set, \n",
    "#   so accuracy will be different each time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for income bracket  0 = 0.705557897272\n",
      "Accuracy for income bracket  1 = 0.665992734867\n",
      "Accuracy for income bracket  2 = 0.00040210557099\n",
      "Accuracy for income bracket  3 = 0.0\n",
      "Accuracy for income bracket  4 = 0.0\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix accuracy per class\n",
    "for i in range(0,len(conf)):\n",
    "    print(\"Accuracy for income bracket \", i, \"=\",conf[i][i]/sum(conf[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as p\n",
    "from scipy.optimize import fmin_bfgs\n",
    "from scipy.special import expit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class BinaryClassifierBase:\n",
    "    def __init__(self, eta, iterations=20, cost=0.001, norm=2):\n",
    "        self.eta = eta\n",
    "        self.cost = cost\n",
    "        self.iters = iterations\n",
    "        self.norm = norm\n",
    "    \n",
    "    def normalize(self, w, gradient):\n",
    "        # regularization (does both if 3)\n",
    "        if self.norm & 1: # L1 norm\n",
    "            gradient[1:] += -1 * w[1:] * self.cost\n",
    "        elif self.norm & 2: # L2 norm\n",
    "            gradient[1:] += -2 * w[1:] * self.cost\n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        self.w_ = np.zeros((x.shape[1],1))\n",
    "        for _ in range(self.iters):\n",
    "            gradient = self._get_gradient(x,y)\n",
    "            self.normalize(self.w_, gradient)\n",
    "            self.w_ += gradient*self.eta\n",
    "    \n",
    "    def predict_proba(self,x):\n",
    "        return 1/(1+np.exp(-(x @ self.w_)))\n",
    "    \n",
    "    def predict(self, x):\n",
    "        return (self.predict_proba(x)>0.5)\n",
    "    \n",
    "    \n",
    "class BinaryStochDescClassifier(BinaryClassifierBase):\n",
    "    def _get_gradient(self, x, y):\n",
    "        idx = int(np.random.rand()*len(y)) # grab random instance\n",
    "        ydiff = y[idx]-self.predict_proba(x[idx]) # get y difference (now scalar)\n",
    "        gradient = x[idx] * ydiff[:,np.newaxis] # make ydiff a column vector and multiply through\n",
    "        gradient = gradient.reshape(self.w_.shape)\n",
    "        return gradient\n",
    "    \n",
    "    \n",
    "class BinarySteepDescClassifier(BinaryClassifierBase):\n",
    "    def _get_gradient(self, x, y):\n",
    "        ydiff = y-self.predict_proba(x).ravel()\n",
    "        gradient = np.mean(x * ydiff[:,np.newaxis], axis=0)\n",
    "        return gradient.reshape(self.w_.shape)\n",
    "\n",
    "    \n",
    "class BinaryNewtonClassifier(BinaryClassifierBase):\n",
    "    def fit(self, x, y):\n",
    "        def obj_fn(w, x, y, c):\n",
    "            g = expit(x @ w)\n",
    "            return -np.sum(np.log(g[y==1]))-np.sum(np.log(1-g[y==0])) + c*sum(w**2)\n",
    "        \n",
    "        def obj_grad(w, x, y, c):\n",
    "            g = expit(x @ w)\n",
    "            ydiff = y-g\n",
    "            gradient = np.mean(x * ydiff[:,np.newaxis], axis=0)\n",
    "            gradient = gradient.reshape(w.shape)\n",
    "            self.normalize(w, gradient)\n",
    "            return -gradient\n",
    "        \n",
    "        self.w_ = fmin_bfgs(obj_fn, \n",
    "                            np.zeros((x.shape[1], 1)), \n",
    "                            fprime=obj_grad, \n",
    "                            args=(x, y, self.cost), \n",
    "                            gtol=1e-03, \n",
    "                            maxiter=self.iters,\n",
    "                            disp=False).reshape((x.shape[1], 1))\n",
    "\n",
    "        \n",
    "class LogRegClassifier:\n",
    "    def __init__(self, eta, iterations=20, optimize='steepdesc', cost=0.001, norm=2):\n",
    "        typesofoptimize = {\n",
    "            'steepdesc': BinarySteepDescClassifier, \n",
    "            'stochdesc': BinaryStochDescClassifier, \n",
    "            'newton': BinaryNewtonClassifier\n",
    "        }\n",
    "        if optimize not in typesofoptimize.keys():\n",
    "            raise ValueError('optimize must be one of: ' + ' '.join(typesofoptimize.keys()))\n",
    "        \n",
    "        self.eta = eta\n",
    "        self.iters = iterations\n",
    "        self.optimize = optimize\n",
    "        self.classifier = typesofoptimize[optimize]\n",
    "        self.cost = cost\n",
    "        self.norm = norm\n",
    "        self.classifiers = [] # fill with binary classifiers during fit\n",
    "    \n",
    "    def _add_bias(self, x):\n",
    "        return np.hstack((np.ones((x.shape[0],1)),x))\n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        Xb = self._add_bias(x)\n",
    "        classes = np.unique(y)\n",
    "        \n",
    "        for cl in classes:\n",
    "            cur_y = y==cl\n",
    "            cur_classifier = self.classifier(self.eta, self.iters, cost=self.cost, norm=self.norm)\n",
    "            cur_classifier.fit(x, cur_y)\n",
    "            self.classifiers.append(cur_classifier)\n",
    "    \n",
    "    def predict(self, x):\n",
    "        if not self.classifiers:\n",
    "            raise RuntimeError('Classifier not fit!')\n",
    "        \n",
    "        probabilities = []\n",
    "        for classifier in self.classifiers:\n",
    "            probabilities.append(classifier.predict_proba(x))\n",
    "        probabilities = np.hstack(probabilities)\n",
    "        return np.argmax(probabilities,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stoch: 0.666666666667\n",
      "steep: 0.813333333333\n",
      "newton: 0.813333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.metrics import accuracy_score\n",
    "ds = load_iris()\n",
    "kwargs = {\n",
    "    'norm': 2,\n",
    "    'cost': .1,\n",
    "    'iterations': 500\n",
    "}\n",
    "regrs = {\n",
    "    'newton': LogRegClassifier(.1, optimize='newton', **kwargs),\n",
    "    'stoch': LogRegClassifier(.1, optimize='stochdesc', **kwargs), # Different results every time, random\n",
    "    'steep': LogRegClassifier(.1, optimize='steepdesc', **kwargs)\n",
    "}\n",
    "for regr in regrs.values():\n",
    "    regr.fit(ds.data, ds.target)\n",
    "\n",
    "for key, val in regrs.items():\n",
    "    res = val.predict(ds.data)\n",
    "    print(key + ': ' +str(accuracy_score(ds.target, res)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_indices' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-f8781f84f20e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_indices' is not defined"
     ]
    }
   ],
   "source": [
    "X_train = X[train_indices]\n",
    "y_train = y[train_indices]\n",
    "\n",
    "X_test = X[test_indices]\n",
    "y_test = y[test_indices]\n",
    "\n",
    "kwargs = {\n",
    "    'norm': 2,\n",
    "    'cost': .1,\n",
    "    'iterations': 500\n",
    "}\n",
    "\n",
    "lr = LogRegClassifier(.1, optimize='steepdesc', **kwargs)\n",
    "lr.fit(X_train,y_train)\n",
    "print(lr)\n",
    "\n",
    "yhat = lr.predict(X_test)\n",
    "\n",
    "print('Accuracy of: ',accuracy_score(y_test,yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
