{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 04\n",
    "\n",
    "## Conrad Appel, Erik Gabrielson, Danh Nguyen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation and Overview (30 points total)\n",
    "\n",
    "[5 points] Explain the task and what business-case or use-case it is designed to solve (or designed to investigate). Detail exactly what the classification task is and what parties would be interested in the results.\n",
    "\n",
    "[10 points] (mostly the same processes as from lab one) Define and prepare your class variables. Use proper variable representations (int, float, one-hot, etc.). Use pre-processing methods (as needed) for dimensionality reduction, scaling, etc. Remove variables that are not needed/useful for the analysis. Describe the final dataset that is used for classification/regression (include a description of any newly formed variables you created).\n",
    "\n",
    "[15 points] Divide you data into training and testing data using an 80% training and 20% testing split. Use the cross validation modules that are part of scikit-learn. Argue for or against splitting your data using an 80/20 split. That is, why is the 80/20 split appropriate (or not) for your dataset?  \n",
    "\n",
    "### Modeling (50 points total)\n",
    "\n",
    "[20 points] Create a custom, one-versus-all logistic regression classifier using numpy and scipy to optimize. Use object oriented conventions identical to scikit-learn. You should start with the template used in the course. You should add the following functionality to the logistic regression classifier:\n",
    "Ability to choose optimization technique when class is instantiated: either steepest descent, stochastic gradient descent, or Newton's method. Update the gradient calculation to include a customizable regularization term (either using no regularization, L1 regularization, L2 regularization, or both L1/L2 norm of the weights). Associate a cost with the regularization term, \"C\", that can be adjusted when the class is instantiated.  \n",
    "\n",
    "[15 points] Train your classifier to achieve good generalization performance. That is, adjust the optimization technique and the value of the regularization term \"C\" to achieve the best performance on your test set. Is your method of selecting parameters justified? That is, do you think there is any \"data snooping\" involved with this method of selecting parameters?\n",
    "\n",
    "[15 points] Compare the performance of your \"best\" logistic regression optimization procedure to the procedure used in scikit-learn. Visualize the performance differences in terms of training time, training iterations, and memory usage while training. Discuss the results. \n",
    "\n",
    "### Deployment (10 points total)\n",
    "\n",
    "Which implementation of logistic regression would you advise be used in a deployed machine learning model, your implementation or scikit-learn (or other third party)? Why?\n",
    "\n",
    "### Exceptional Work (10 points total)\n",
    "\n",
    "You have free reign to provide additional analyses.\n",
    "One idea: Make your implementation of logistic regression compatible with the GridSearchCV function that is part of scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as p\n",
    "from scipy.optimize import fmin_bfgs\n",
    "from scipy.special import expit\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.utils.estimator_checks import check_estimator\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class BinaryClassifierBase:\n",
    "    def __init__(self, eta, iters=20, cost=0.001, norm=2):\n",
    "        self.eta = eta\n",
    "        self.cost = cost\n",
    "        self.iters = iters\n",
    "        self.norm = norm\n",
    "    \n",
    "    def normalize(self, w, gradient):\n",
    "        # regularization (does both if 3)\n",
    "        if self.norm & 1: # L1 norm\n",
    "            gradient[1:] += -1 * w[1:] * self.cost\n",
    "        elif self.norm & 2: # L2 norm\n",
    "            gradient[1:] += -2 * w[1:] * self.cost\n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        self.w_ = np.zeros((x.shape[1],1))\n",
    "        for _ in range(self.iters):\n",
    "            gradient = self._get_gradient(x,y)\n",
    "            self.normalize(self.w_, gradient)\n",
    "            self.w_ += gradient*self.eta\n",
    "    \n",
    "    def predict_proba(self,x):\n",
    "        return 1/(1+np.exp(-(x @ self.w_)))\n",
    "    \n",
    "    def predict(self, x):\n",
    "        return (self.predict_proba(x)>0.5)\n",
    "    \n",
    "    \n",
    "class BinaryStochDescClassifier(BinaryClassifierBase):\n",
    "    def _get_gradient(self, x, y):\n",
    "        idx = int(np.random.rand()*len(y)) # grab random instance\n",
    "        ydiff = y[idx]-self.predict_proba(x[idx]) # get y difference (now scalar)\n",
    "        gradient = x[idx] * ydiff[:,np.newaxis] # make ydiff a column vector and multiply through\n",
    "        gradient = gradient.reshape(self.w_.shape)\n",
    "        return gradient\n",
    "    \n",
    "    \n",
    "class BinarySteepDescClassifier(BinaryClassifierBase):\n",
    "    def _get_gradient(self, x, y):\n",
    "        ydiff = y-self.predict_proba(x).ravel()\n",
    "        gradient = np.mean(x * ydiff[:,np.newaxis], axis=0)\n",
    "        return gradient.reshape(self.w_.shape)\n",
    "\n",
    "    \n",
    "class BinaryNewtonClassifier(BinaryClassifierBase):\n",
    "    def fit(self, x, y):\n",
    "        def obj_fn(w, x, y, c):\n",
    "            g = expit(x @ w)\n",
    "            return -np.sum(np.log(g[y==1]))-np.sum(np.log(1-g[y==0])) + c*sum(w**2)\n",
    "        \n",
    "        def obj_grad(w, x, y, c):\n",
    "            g = expit(x @ w)\n",
    "            ydiff = y-g\n",
    "            gradient = np.mean(x * ydiff[:,np.newaxis], axis=0)\n",
    "            gradient = gradient.reshape(w.shape)\n",
    "            self.normalize(w, gradient)\n",
    "            return -gradient\n",
    "        \n",
    "        self.w_ = fmin_bfgs(obj_fn, \n",
    "                            np.zeros((x.shape[1], 1)), \n",
    "                            fprime=obj_grad, \n",
    "                            args=(x, y, self.cost), \n",
    "                            gtol=1e-03, \n",
    "                            maxiter=self.iters,\n",
    "                            disp=False).reshape((x.shape[1], 1))\n",
    "\n",
    "        \n",
    "class LogRegClassifier:\n",
    "    def __init__(self, eta=.0001, iters=20, optimize='steepdesc', cost=0.001, norm=2):\n",
    "        self._set_optimization(optimize)\n",
    "        self.eta = eta\n",
    "        self.iters = iters\n",
    "        self.cost = cost\n",
    "        self.norm = norm\n",
    "        \n",
    "        self.classifiers = [] # fill with binary classifiers during fit\n",
    "        self._estimator_type = 'classifier'\n",
    "    \n",
    "    def _add_bias(self, x):\n",
    "        return np.hstack((np.ones((x.shape[0],1)),x))\n",
    "    \n",
    "    def _set_optimization(self, optimize):\n",
    "        typesofoptimize = {\n",
    "            'steepdesc': BinarySteepDescClassifier, \n",
    "            'stochdesc': BinaryStochDescClassifier, \n",
    "            'newton': BinaryNewtonClassifier\n",
    "        }\n",
    "        if optimize not in typesofoptimize.keys():\n",
    "            raise ValueError('optimize must be one of: ' + ' '.join(typesofoptimize.keys()))\n",
    "            \n",
    "        self.optimize = optimize\n",
    "        self.classifier = typesofoptimize[optimize]\n",
    "        \n",
    "    def fit(self, x, y):\n",
    "        x, y = check_X_y(x, y)\n",
    "        \n",
    "        Xb = self._add_bias(x)\n",
    "        self.classes_ = np.unique(y)\n",
    "        self.X_ = x\n",
    "        self.y_ = y\n",
    "        \n",
    "        for cl in self.classes_:\n",
    "            cur_y = y==cl\n",
    "            cur_classifier = self.classifier(self.eta, self.iters, cost=self.cost, norm=self.norm)\n",
    "            cur_classifier.fit(x, cur_y)\n",
    "            self.classifiers.append(cur_classifier)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, x):\n",
    "        check_is_fitted(self, ['X_', 'y_'])\n",
    "        x = check_array(x)\n",
    "        \n",
    "        probabilities = []\n",
    "        for classifier in self.classifiers:\n",
    "            probabilities.append(classifier.predict_proba(x))\n",
    "        probabilities = np.hstack(probabilities)\n",
    "        return np.argmax(probabilities,axis=1)\n",
    "    \n",
    "    def score(self, x, y):\n",
    "        res = self.predict(x)\n",
    "        return accuracy_score(y, res)\n",
    "    \n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            setattr(self, parameter, value)\n",
    "        return self\n",
    "            \n",
    "    def get_params(self, deep=True):\n",
    "        return {\n",
    "            'eta': self.eta,\n",
    "            'iters': self.iters,\n",
    "            'optimize': self.optimize,\n",
    "            'cost': self.cost,\n",
    "            'norm': self.norm\n",
    "        }\n",
    "    \n",
    "check_estimator(LogRegClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stoch: 0.693333333333\n",
      "steep: 0.953333333333\n",
      "newton: 0.966666666667\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ds = load_iris()\n",
    "kwargs = {\n",
    "    'norm': 2,\n",
    "    'cost': .001,\n",
    "    'iters': 500\n",
    "}\n",
    "regrs = {\n",
    "    'newton': LogRegClassifier(eta=.1, optimize='newton', **kwargs),\n",
    "    'stoch': LogRegClassifier(eta=.1, optimize='stochdesc', **kwargs), # Different results every time, random\n",
    "    'steep': LogRegClassifier(eta=.1, optimize='steepdesc', **kwargs)\n",
    "}\n",
    "for regr in regrs.values():\n",
    "    regr.fit(ds.data, ds.target)\n",
    "\n",
    "for key, val in regrs.items():\n",
    "    res = val.predict(ds.data)\n",
    "    print(key + ': ' +str(accuracy_score(ds.target, res)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "method: newton, eta: 0.0001, norm: 0, cost: 0.0001 ----> 0.96%\n",
      "method: newton, eta: 0.0001, norm: 0, cost: 0.001 ----> 0.966666666667%\n",
      "method: newton, eta: 0.0001, norm: 0, cost: 0.01 ----> 0.973333333333%\n",
      "method: newton, eta: 0.0001, norm: 0, cost: 0.1 ----> 0.966666666667%\n",
      "method: newton, eta: 0.0001, norm: 0, cost: 0.25 ----> 0.966666666667%\n",
      "method: newton, eta: 0.0001, norm: 0, cost: 0.5 ----> 0.953333333333%\n",
      "method: newton, eta: 0.0001, norm: 1, cost: 0.0001 ----> 0.96%\n",
      "method: newton, eta: 0.0001, norm: 1, cost: 0.001 ----> 0.966666666667%\n",
      "method: newton, eta: 0.0001, norm: 1, cost: 0.01 ----> 0.953333333333%\n",
      "method: newton, eta: 0.0001, norm: 1, cost: 0.1 ----> 0.873333333333%\n",
      "method: newton, eta: 0.0001, norm: 1, cost: 0.25 ----> 0.786666666667%\n",
      "method: newton, eta: 0.0001, norm: 1, cost: 0.5 ----> 0.666666666667%\n",
      "method: newton, eta: 0.0001, norm: 2, cost: 0.0001 ----> 0.973333333333%\n",
      "method: newton, eta: 0.0001, norm: 2, cost: 0.001 ----> 0.966666666667%\n",
      "method: newton, eta: 0.0001, norm: 2, cost: 0.01 ----> 0.953333333333%\n",
      "method: newton, eta: 0.0001, norm: 2, cost: 0.1 ----> 0.813333333333%\n",
      "method: newton, eta: 0.0001, norm: 2, cost: 0.25 ----> 0.666666666667%\n",
      "method: newton, eta: 0.0001, norm: 2, cost: 0.5 ----> 0.666666666667%\n",
      "method: newton, eta: 0.0001, norm: 3, cost: 0.0001 ----> 0.96%\n",
      "method: newton, eta: 0.0001, norm: 3, cost: 0.001 ----> 0.966666666667%\n",
      "method: newton, eta: 0.0001, norm: 3, cost: 0.01 ----> 0.953333333333%\n",
      "method: newton, eta: 0.0001, norm: 3, cost: 0.1 ----> 0.873333333333%\n",
      "method: newton, eta: 0.0001, norm: 3, cost: 0.25 ----> 0.786666666667%\n",
      "method: newton, eta: 0.0001, norm: 3, cost: 0.5 ----> 0.666666666667%\n",
      "method: newton, eta: 0.001, norm: 0, cost: 0.0001 ----> 0.96%\n",
      "method: newton, eta: 0.001, norm: 0, cost: 0.001 ----> 0.966666666667%\n",
      "method: newton, eta: 0.001, norm: 0, cost: 0.01 ----> 0.973333333333%\n",
      "method: newton, eta: 0.001, norm: 0, cost: 0.1 ----> 0.966666666667%\n",
      "method: newton, eta: 0.001, norm: 0, cost: 0.25 ----> 0.966666666667%\n",
      "method: newton, eta: 0.001, norm: 0, cost: 0.5 ----> 0.953333333333%\n",
      "method: newton, eta: 0.001, norm: 1, cost: 0.0001 ----> 0.96%\n",
      "method: newton, eta: 0.001, norm: 1, cost: 0.001 ----> 0.966666666667%\n",
      "method: newton, eta: 0.001, norm: 1, cost: 0.01 ----> 0.953333333333%\n",
      "method: newton, eta: 0.001, norm: 1, cost: 0.1 ----> 0.873333333333%\n",
      "method: newton, eta: 0.001, norm: 1, cost: 0.25 ----> 0.786666666667%\n",
      "method: newton, eta: 0.001, norm: 1, cost: 0.5 ----> 0.666666666667%\n",
      "method: newton, eta: 0.001, norm: 2, cost: 0.0001 ----> 0.973333333333%\n",
      "method: newton, eta: 0.001, norm: 2, cost: 0.001 ----> 0.966666666667%\n",
      "method: newton, eta: 0.001, norm: 2, cost: 0.01 ----> 0.953333333333%\n",
      "method: newton, eta: 0.001, norm: 2, cost: 0.1 ----> 0.813333333333%\n",
      "method: newton, eta: 0.001, norm: 2, cost: 0.25 ----> 0.666666666667%\n",
      "method: newton, eta: 0.001, norm: 2, cost: 0.5 ----> 0.666666666667%\n",
      "method: newton, eta: 0.001, norm: 3, cost: 0.0001 ----> 0.96%\n",
      "method: newton, eta: 0.001, norm: 3, cost: 0.001 ----> 0.966666666667%\n",
      "method: newton, eta: 0.001, norm: 3, cost: 0.01 ----> 0.953333333333%\n",
      "method: newton, eta: 0.001, norm: 3, cost: 0.1 ----> 0.873333333333%\n",
      "method: newton, eta: 0.001, norm: 3, cost: 0.25 ----> 0.786666666667%\n",
      "method: newton, eta: 0.001, norm: 3, cost: 0.5 ----> 0.666666666667%\n",
      "method: newton, eta: 0.01, norm: 0, cost: 0.0001 ----> 0.96%\n",
      "method: newton, eta: 0.01, norm: 0, cost: 0.001 ----> 0.966666666667%\n",
      "method: newton, eta: 0.01, norm: 0, cost: 0.01 ----> 0.973333333333%\n",
      "method: newton, eta: 0.01, norm: 0, cost: 0.1 ----> 0.966666666667%\n",
      "method: newton, eta: 0.01, norm: 0, cost: 0.25 ----> 0.966666666667%\n",
      "method: newton, eta: 0.01, norm: 0, cost: 0.5 ----> 0.953333333333%\n",
      "method: newton, eta: 0.01, norm: 1, cost: 0.0001 ----> 0.96%\n",
      "method: newton, eta: 0.01, norm: 1, cost: 0.001 ----> 0.966666666667%\n",
      "method: newton, eta: 0.01, norm: 1, cost: 0.01 ----> 0.953333333333%\n",
      "method: newton, eta: 0.01, norm: 1, cost: 0.1 ----> 0.873333333333%\n",
      "method: newton, eta: 0.01, norm: 1, cost: 0.25 ----> 0.786666666667%\n",
      "method: newton, eta: 0.01, norm: 1, cost: 0.5 ----> 0.666666666667%\n",
      "method: newton, eta: 0.01, norm: 2, cost: 0.0001 ----> 0.973333333333%\n",
      "method: newton, eta: 0.01, norm: 2, cost: 0.001 ----> 0.966666666667%\n",
      "method: newton, eta: 0.01, norm: 2, cost: 0.01 ----> 0.953333333333%\n",
      "method: newton, eta: 0.01, norm: 2, cost: 0.1 ----> 0.813333333333%\n",
      "method: newton, eta: 0.01, norm: 2, cost: 0.25 ----> 0.666666666667%\n",
      "method: newton, eta: 0.01, norm: 2, cost: 0.5 ----> 0.666666666667%\n",
      "method: newton, eta: 0.01, norm: 3, cost: 0.0001 ----> 0.96%\n",
      "method: newton, eta: 0.01, norm: 3, cost: 0.001 ----> 0.966666666667%\n",
      "method: newton, eta: 0.01, norm: 3, cost: 0.01 ----> 0.953333333333%\n",
      "method: newton, eta: 0.01, norm: 3, cost: 0.1 ----> 0.873333333333%\n",
      "method: newton, eta: 0.01, norm: 3, cost: 0.25 ----> 0.786666666667%\n",
      "method: newton, eta: 0.01, norm: 3, cost: 0.5 ----> 0.666666666667%\n",
      "method: newton, eta: 0.1, norm: 0, cost: 0.0001 ----> 0.96%\n",
      "method: newton, eta: 0.1, norm: 0, cost: 0.001 ----> 0.966666666667%\n",
      "method: newton, eta: 0.1, norm: 0, cost: 0.01 ----> 0.973333333333%\n",
      "method: newton, eta: 0.1, norm: 0, cost: 0.1 ----> 0.966666666667%\n",
      "method: newton, eta: 0.1, norm: 0, cost: 0.25 ----> 0.966666666667%\n",
      "method: newton, eta: 0.1, norm: 0, cost: 0.5 ----> 0.953333333333%\n",
      "method: newton, eta: 0.1, norm: 1, cost: 0.0001 ----> 0.96%\n",
      "method: newton, eta: 0.1, norm: 1, cost: 0.001 ----> 0.966666666667%\n",
      "method: newton, eta: 0.1, norm: 1, cost: 0.01 ----> 0.953333333333%\n",
      "method: newton, eta: 0.1, norm: 1, cost: 0.1 ----> 0.873333333333%\n",
      "method: newton, eta: 0.1, norm: 1, cost: 0.25 ----> 0.786666666667%\n",
      "method: newton, eta: 0.1, norm: 1, cost: 0.5 ----> 0.666666666667%\n",
      "method: newton, eta: 0.1, norm: 2, cost: 0.0001 ----> 0.973333333333%\n",
      "method: newton, eta: 0.1, norm: 2, cost: 0.001 ----> 0.966666666667%\n",
      "method: newton, eta: 0.1, norm: 2, cost: 0.01 ----> 0.953333333333%\n",
      "method: newton, eta: 0.1, norm: 2, cost: 0.1 ----> 0.813333333333%\n",
      "method: newton, eta: 0.1, norm: 2, cost: 0.25 ----> 0.666666666667%\n",
      "method: newton, eta: 0.1, norm: 2, cost: 0.5 ----> 0.666666666667%\n",
      "method: newton, eta: 0.1, norm: 3, cost: 0.0001 ----> 0.96%\n",
      "method: newton, eta: 0.1, norm: 3, cost: 0.001 ----> 0.966666666667%\n",
      "method: newton, eta: 0.1, norm: 3, cost: 0.01 ----> 0.953333333333%\n",
      "method: newton, eta: 0.1, norm: 3, cost: 0.1 ----> 0.873333333333%\n",
      "method: newton, eta: 0.1, norm: 3, cost: 0.25 ----> 0.786666666667%\n",
      "method: newton, eta: 0.1, norm: 3, cost: 0.5 ----> 0.666666666667%\n",
      "method: newton, eta: 0.25, norm: 0, cost: 0.0001 ----> 0.96%\n",
      "method: newton, eta: 0.25, norm: 0, cost: 0.001 ----> 0.966666666667%\n",
      "method: newton, eta: 0.25, norm: 0, cost: 0.01 ----> 0.973333333333%\n",
      "method: newton, eta: 0.25, norm: 0, cost: 0.1 ----> 0.966666666667%\n",
      "method: newton, eta: 0.25, norm: 0, cost: 0.25 ----> 0.966666666667%\n",
      "method: newton, eta: 0.25, norm: 0, cost: 0.5 ----> 0.953333333333%\n",
      "method: newton, eta: 0.25, norm: 1, cost: 0.0001 ----> 0.96%\n",
      "method: newton, eta: 0.25, norm: 1, cost: 0.001 ----> 0.966666666667%\n",
      "method: newton, eta: 0.25, norm: 1, cost: 0.01 ----> 0.953333333333%\n",
      "method: newton, eta: 0.25, norm: 1, cost: 0.1 ----> 0.873333333333%\n",
      "method: newton, eta: 0.25, norm: 1, cost: 0.25 ----> 0.786666666667%\n",
      "method: newton, eta: 0.25, norm: 1, cost: 0.5 ----> 0.666666666667%\n",
      "method: newton, eta: 0.25, norm: 2, cost: 0.0001 ----> 0.973333333333%\n",
      "method: newton, eta: 0.25, norm: 2, cost: 0.001 ----> 0.966666666667%\n",
      "method: newton, eta: 0.25, norm: 2, cost: 0.01 ----> 0.953333333333%\n",
      "method: newton, eta: 0.25, norm: 2, cost: 0.1 ----> 0.813333333333%\n",
      "method: newton, eta: 0.25, norm: 2, cost: 0.25 ----> 0.666666666667%\n",
      "method: newton, eta: 0.25, norm: 2, cost: 0.5 ----> 0.666666666667%\n",
      "method: newton, eta: 0.25, norm: 3, cost: 0.0001 ----> 0.96%\n",
      "method: newton, eta: 0.25, norm: 3, cost: 0.001 ----> 0.966666666667%\n",
      "method: newton, eta: 0.25, norm: 3, cost: 0.01 ----> 0.953333333333%\n",
      "method: newton, eta: 0.25, norm: 3, cost: 0.1 ----> 0.873333333333%\n",
      "method: newton, eta: 0.25, norm: 3, cost: 0.25 ----> 0.786666666667%\n",
      "method: newton, eta: 0.25, norm: 3, cost: 0.5 ----> 0.666666666667%\n",
      "method: newton, eta: 0.5, norm: 0, cost: 0.0001 ----> 0.96%\n",
      "method: newton, eta: 0.5, norm: 0, cost: 0.001 ----> 0.966666666667%\n",
      "method: newton, eta: 0.5, norm: 0, cost: 0.01 ----> 0.973333333333%\n",
      "method: newton, eta: 0.5, norm: 0, cost: 0.1 ----> 0.966666666667%\n",
      "method: newton, eta: 0.5, norm: 0, cost: 0.25 ----> 0.966666666667%\n",
      "method: newton, eta: 0.5, norm: 0, cost: 0.5 ----> 0.953333333333%\n",
      "method: newton, eta: 0.5, norm: 1, cost: 0.0001 ----> 0.96%\n",
      "method: newton, eta: 0.5, norm: 1, cost: 0.001 ----> 0.966666666667%\n",
      "method: newton, eta: 0.5, norm: 1, cost: 0.01 ----> 0.953333333333%\n",
      "method: newton, eta: 0.5, norm: 1, cost: 0.1 ----> 0.873333333333%\n",
      "method: newton, eta: 0.5, norm: 1, cost: 0.25 ----> 0.786666666667%\n",
      "method: newton, eta: 0.5, norm: 1, cost: 0.5 ----> 0.666666666667%\n",
      "method: newton, eta: 0.5, norm: 2, cost: 0.0001 ----> 0.973333333333%\n",
      "method: newton, eta: 0.5, norm: 2, cost: 0.001 ----> 0.966666666667%\n",
      "method: newton, eta: 0.5, norm: 2, cost: 0.01 ----> 0.953333333333%\n",
      "method: newton, eta: 0.5, norm: 2, cost: 0.1 ----> 0.813333333333%\n",
      "method: newton, eta: 0.5, norm: 2, cost: 0.25 ----> 0.666666666667%\n",
      "method: newton, eta: 0.5, norm: 2, cost: 0.5 ----> 0.666666666667%\n",
      "method: newton, eta: 0.5, norm: 3, cost: 0.0001 ----> 0.96%\n",
      "method: newton, eta: 0.5, norm: 3, cost: 0.001 ----> 0.966666666667%\n",
      "method: newton, eta: 0.5, norm: 3, cost: 0.01 ----> 0.953333333333%\n",
      "method: newton, eta: 0.5, norm: 3, cost: 0.1 ----> 0.873333333333%\n",
      "method: newton, eta: 0.5, norm: 3, cost: 0.25 ----> 0.786666666667%\n",
      "method: newton, eta: 0.5, norm: 3, cost: 0.5 ----> 0.666666666667%\n",
      "method: stochdesc, eta: 0.0001, norm: 0, cost: 0.0001 ----> 0.333333333333%\n",
      "method: stochdesc, eta: 0.0001, norm: 0, cost: 0.001 ----> 0.333333333333%\n",
      "method: stochdesc, eta: 0.0001, norm: 0, cost: 0.01 ----> 0.333333333333%\n",
      "method: stochdesc, eta: 0.0001, norm: 0, cost: 0.1 ----> 0.333333333333%\n",
      "method: stochdesc, eta: 0.0001, norm: 0, cost: 0.25 ----> 0.333333333333%\n",
      "method: stochdesc, eta: 0.0001, norm: 0, cost: 0.5 ----> 0.333333333333%\n",
      "method: stochdesc, eta: 0.0001, norm: 1, cost: 0.0001 ----> 0.333333333333%\n",
      "method: stochdesc, eta: 0.0001, norm: 1, cost: 0.001 ----> 0.333333333333%\n",
      "method: stochdesc, eta: 0.0001, norm: 1, cost: 0.01 ----> 0.333333333333%\n",
      "method: stochdesc, eta: 0.0001, norm: 1, cost: 0.1 ----> 0.333333333333%\n",
      "method: stochdesc, eta: 0.0001, norm: 1, cost: 0.25 ----> 0.333333333333%\n",
      "method: stochdesc, eta: 0.0001, norm: 1, cost: 0.5 ----> 0.333333333333%\n",
      "method: stochdesc, eta: 0.0001, norm: 2, cost: 0.0001 ----> 0.333333333333%\n",
      "method: stochdesc, eta: 0.0001, norm: 2, cost: 0.001 ----> 0.333333333333%\n",
      "method: stochdesc, eta: 0.0001, norm: 2, cost: 0.01 ----> 0.353333333333%\n",
      "method: stochdesc, eta: 0.0001, norm: 2, cost: 0.1 ----> 0.333333333333%\n",
      "method: stochdesc, eta: 0.0001, norm: 2, cost: 0.25 ----> 0.333333333333%\n",
      "method: stochdesc, eta: 0.0001, norm: 2, cost: 0.5 ----> 0.333333333333%\n",
      "method: stochdesc, eta: 0.0001, norm: 3, cost: 0.0001 ----> 0.333333333333%\n",
      "method: stochdesc, eta: 0.0001, norm: 3, cost: 0.001 ----> 0.333333333333%\n",
      "method: stochdesc, eta: 0.0001, norm: 3, cost: 0.01 ----> 0.333333333333%\n",
      "method: stochdesc, eta: 0.0001, norm: 3, cost: 0.1 ----> 0.333333333333%\n",
      "method: stochdesc, eta: 0.0001, norm: 3, cost: 0.25 ----> 0.333333333333%\n",
      "method: stochdesc, eta: 0.0001, norm: 3, cost: 0.5 ----> 0.333333333333%\n",
      "method: stochdesc, eta: 0.001, norm: 0, cost: 0.0001 ----> 0.666666666667%\n",
      "method: stochdesc, eta: 0.001, norm: 0, cost: 0.001 ----> 0.666666666667%\n",
      "method: stochdesc, eta: 0.001, norm: 0, cost: 0.01 ----> 0.953333333333%\n",
      "method: stochdesc, eta: 0.001, norm: 0, cost: 0.1 ----> 0.806666666667%\n",
      "method: stochdesc, eta: 0.001, norm: 0, cost: 0.25 ----> 0.666666666667%\n",
      "method: stochdesc, eta: 0.001, norm: 0, cost: 0.5 ----> 0.666666666667%\n",
      "method: stochdesc, eta: 0.001, norm: 1, cost: 0.0001 ----> 0.666666666667%\n",
      "method: stochdesc, eta: 0.001, norm: 1, cost: 0.001 ----> 0.78%\n",
      "method: stochdesc, eta: 0.001, norm: 1, cost: 0.01 ----> 0.666666666667%\n",
      "method: stochdesc, eta: 0.001, norm: 1, cost: 0.1 ----> 0.666666666667%\n",
      "method: stochdesc, eta: 0.001, norm: 1, cost: 0.25 ----> 0.6%\n",
      "method: stochdesc, eta: 0.001, norm: 1, cost: 0.5 ----> 0.706666666667%\n",
      "method: stochdesc, eta: 0.001, norm: 2, cost: 0.0001 ----> 0.666666666667%\n",
      "method: stochdesc, eta: 0.001, norm: 2, cost: 0.001 ----> 0.906666666667%\n",
      "method: stochdesc, eta: 0.001, norm: 2, cost: 0.01 ----> 0.666666666667%\n",
      "method: stochdesc, eta: 0.001, norm: 2, cost: 0.1 ----> 0.673333333333%\n",
      "method: stochdesc, eta: 0.001, norm: 2, cost: 0.25 ----> 0.833333333333%\n",
      "method: stochdesc, eta: 0.001, norm: 2, cost: 0.5 ----> 0.666666666667%\n",
      "method: stochdesc, eta: 0.001, norm: 3, cost: 0.0001 ----> 0.666666666667%\n",
      "method: stochdesc, eta: 0.001, norm: 3, cost: 0.001 ----> 0.666666666667%\n",
      "method: stochdesc, eta: 0.001, norm: 3, cost: 0.01 ----> 0.666666666667%\n",
      "method: stochdesc, eta: 0.001, norm: 3, cost: 0.1 ----> 0.666666666667%\n",
      "method: stochdesc, eta: 0.001, norm: 3, cost: 0.25 ----> 0.78%\n",
      "method: stochdesc, eta: 0.001, norm: 3, cost: 0.5 ----> 0.666666666667%\n",
      "method: stochdesc, eta: 0.01, norm: 0, cost: 0.0001 ----> 0.68%\n",
      "method: stochdesc, eta: 0.01, norm: 0, cost: 0.001 ----> 0.666666666667%\n",
      "method: stochdesc, eta: 0.01, norm: 0, cost: 0.01 ----> 0.666666666667%\n",
      "method: stochdesc, eta: 0.01, norm: 0, cost: 0.1 ----> 0.906666666667%\n",
      "method: stochdesc, eta: 0.01, norm: 0, cost: 0.25 ----> 0.666666666667%\n",
      "method: stochdesc, eta: 0.01, norm: 0, cost: 0.5 ----> 0.673333333333%\n",
      "method: stochdesc, eta: 0.01, norm: 1, cost: 0.0001 ----> 0.853333333333%\n",
      "method: stochdesc, eta: 0.01, norm: 1, cost: 0.001 ----> 0.686666666667%\n",
      "method: stochdesc, eta: 0.01, norm: 1, cost: 0.01 ----> 0.92%\n",
      "method: stochdesc, eta: 0.01, norm: 1, cost: 0.1 ----> 0.84%\n",
      "method: stochdesc, eta: 0.01, norm: 1, cost: 0.25 ----> 0.666666666667%\n",
      "method: stochdesc, eta: 0.01, norm: 1, cost: 0.5 ----> 0.666666666667%\n",
      "method: stochdesc, eta: 0.01, norm: 2, cost: 0.0001 ----> 0.673333333333%\n",
      "method: stochdesc, eta: 0.01, norm: 2, cost: 0.001 ----> 0.7%\n",
      "method: stochdesc, eta: 0.01, norm: 2, cost: 0.01 ----> 0.666666666667%\n",
      "method: stochdesc, eta: 0.01, norm: 2, cost: 0.1 ----> 0.753333333333%\n",
      "method: stochdesc, eta: 0.01, norm: 2, cost: 0.25 ----> 0.666666666667%\n",
      "method: stochdesc, eta: 0.01, norm: 2, cost: 0.5 ----> 0.666666666667%\n",
      "method: stochdesc, eta: 0.01, norm: 3, cost: 0.0001 ----> 0.666666666667%\n",
      "method: stochdesc, eta: 0.01, norm: 3, cost: 0.001 ----> 0.966666666667%\n",
      "method: stochdesc, eta: 0.01, norm: 3, cost: 0.01 ----> 0.666666666667%\n",
      "method: stochdesc, eta: 0.01, norm: 3, cost: 0.1 ----> 0.933333333333%\n",
      "method: stochdesc, eta: 0.01, norm: 3, cost: 0.25 ----> 0.873333333333%\n",
      "method: stochdesc, eta: 0.01, norm: 3, cost: 0.5 ----> 0.873333333333%\n",
      "method: stochdesc, eta: 0.1, norm: 0, cost: 0.0001 ----> 0.96%\n",
      "method: stochdesc, eta: 0.1, norm: 0, cost: 0.001 ----> 0.673333333333%\n",
      "method: stochdesc, eta: 0.1, norm: 0, cost: 0.01 ----> 0.673333333333%\n",
      "method: stochdesc, eta: 0.1, norm: 0, cost: 0.1 ----> 0.793333333333%\n",
      "method: stochdesc, eta: 0.1, norm: 0, cost: 0.25 ----> 0.666666666667%\n",
      "method: stochdesc, eta: 0.1, norm: 0, cost: 0.5 ----> 0.666666666667%\n",
      "method: stochdesc, eta: 0.1, norm: 1, cost: 0.0001 ----> 0.733333333333%\n",
      "method: stochdesc, eta: 0.1, norm: 1, cost: 0.001 ----> 0.68%\n",
      "method: stochdesc, eta: 0.1, norm: 1, cost: 0.01 ----> 0.846666666667%\n",
      "method: stochdesc, eta: 0.1, norm: 1, cost: 0.1 ----> 0.546666666667%\n",
      "method: stochdesc, eta: 0.1, norm: 1, cost: 0.25 ----> 0.666666666667%\n",
      "method: stochdesc, eta: 0.1, norm: 1, cost: 0.5 ----> 0.333333333333%\n",
      "method: stochdesc, eta: 0.1, norm: 2, cost: 0.0001 ----> 0.773333333333%\n",
      "method: stochdesc, eta: 0.1, norm: 2, cost: 0.001 ----> 0.666666666667%\n",
      "method: stochdesc, eta: 0.1, norm: 2, cost: 0.01 ----> 0.96%\n",
      "method: stochdesc, eta: 0.1, norm: 2, cost: 0.1 ----> 0.526666666667%\n",
      "method: stochdesc, eta: 0.1, norm: 2, cost: 0.25 ----> 0.666666666667%\n",
      "method: stochdesc, eta: 0.1, norm: 2, cost: 0.5 ----> 0.333333333333%\n",
      "method: stochdesc, eta: 0.1, norm: 3, cost: 0.0001 ----> 0.666666666667%\n",
      "method: stochdesc, eta: 0.1, norm: 3, cost: 0.001 ----> 0.673333333333%\n",
      "method: stochdesc, eta: 0.1, norm: 3, cost: 0.01 ----> 0.72%\n",
      "method: stochdesc, eta: 0.1, norm: 3, cost: 0.1 ----> 0.666666666667%\n",
      "method: stochdesc, eta: 0.1, norm: 3, cost: 0.25 ----> 0.666666666667%\n",
      "method: stochdesc, eta: 0.1, norm: 3, cost: 0.5 ----> 0.666666666667%\n",
      "method: stochdesc, eta: 0.25, norm: 0, cost: 0.0001 ----> 0.6%\n",
      "method: stochdesc, eta: 0.25, norm: 0, cost: 0.001 ----> 0.866666666667%\n",
      "method: stochdesc, eta: 0.25, norm: 0, cost: 0.01 ----> 0.666666666667%\n",
      "method: stochdesc, eta: 0.25, norm: 0, cost: 0.1 ----> 0.666666666667%\n",
      "method: stochdesc, eta: 0.25, norm: 0, cost: 0.25 ----> 0.673333333333%\n",
      "method: stochdesc, eta: 0.25, norm: 0, cost: 0.5 ----> 0.673333333333%\n",
      "method: stochdesc, eta: 0.25, norm: 1, cost: 0.0001 ----> 0.82%\n",
      "method: stochdesc, eta: 0.25, norm: 1, cost: 0.001 ----> 0.673333333333%\n",
      "method: stochdesc, eta: 0.25, norm: 1, cost: 0.01 ----> 0.713333333333%\n",
      "method: stochdesc, eta: 0.25, norm: 1, cost: 0.1 ----> 0.333333333333%\n",
      "method: stochdesc, eta: 0.25, norm: 1, cost: 0.25 ----> 0.66%\n",
      "method: stochdesc, eta: 0.25, norm: 1, cost: 0.5 ----> 0.333333333333%\n",
      "method: stochdesc, eta: 0.25, norm: 2, cost: 0.0001 ----> 0.96%\n",
      "method: stochdesc, eta: 0.25, norm: 2, cost: 0.001 ----> 0.666666666667%\n",
      "method: stochdesc, eta: 0.25, norm: 2, cost: 0.01 ----> 0.666666666667%\n",
      "method: stochdesc, eta: 0.25, norm: 2, cost: 0.1 ----> 0.646666666667%\n",
      "method: stochdesc, eta: 0.25, norm: 2, cost: 0.25 ----> 0.333333333333%\n",
      "method: stochdesc, eta: 0.25, norm: 2, cost: 0.5 ----> 0.333333333333%\n",
      "method: stochdesc, eta: 0.25, norm: 3, cost: 0.0001 ----> 0.666666666667%\n",
      "method: stochdesc, eta: 0.25, norm: 3, cost: 0.001 ----> 0.693333333333%\n",
      "method: stochdesc, eta: 0.25, norm: 3, cost: 0.01 ----> 0.666666666667%\n",
      "method: stochdesc, eta: 0.25, norm: 3, cost: 0.1 ----> 0.5%\n",
      "method: stochdesc, eta: 0.25, norm: 3, cost: 0.25 ----> 0.393333333333%\n",
      "method: stochdesc, eta: 0.25, norm: 3, cost: 0.5 ----> 0.333333333333%\n",
      "method: stochdesc, eta: 0.5, norm: 0, cost: 0.0001 ----> 0.666666666667%\n",
      "method: stochdesc, eta: 0.5, norm: 0, cost: 0.001 ----> 0.666666666667%\n",
      "method: stochdesc, eta: 0.5, norm: 0, cost: 0.01 ----> 0.74%\n",
      "method: stochdesc, eta: 0.5, norm: 0, cost: 0.1 ----> 0.966666666667%\n",
      "method: stochdesc, eta: 0.5, norm: 0, cost: 0.25 ----> 0.666666666667%\n",
      "method: stochdesc, eta: 0.5, norm: 0, cost: 0.5 ----> 0.68%\n",
      "method: stochdesc, eta: 0.5, norm: 1, cost: 0.0001 ----> 0.786666666667%\n",
      "method: stochdesc, eta: 0.5, norm: 1, cost: 0.001 ----> 0.606666666667%\n",
      "method: stochdesc, eta: 0.5, norm: 1, cost: 0.01 ----> 0.78%\n",
      "method: stochdesc, eta: 0.5, norm: 1, cost: 0.1 ----> 0.666666666667%\n",
      "method: stochdesc, eta: 0.5, norm: 1, cost: 0.25 ----> 0.333333333333%\n",
      "method: stochdesc, eta: 0.5, norm: 1, cost: 0.5 ----> 0.333333333333%\n",
      "method: stochdesc, eta: 0.5, norm: 2, cost: 0.0001 ----> 0.846666666667%\n",
      "method: stochdesc, eta: 0.5, norm: 2, cost: 0.001 ----> 0.666666666667%\n",
      "method: stochdesc, eta: 0.5, norm: 2, cost: 0.01 ----> 0.666666666667%\n",
      "method: stochdesc, eta: 0.5, norm: 2, cost: 0.1 ----> 0.333333333333%\n",
      "method: stochdesc, eta: 0.5, norm: 2, cost: 0.25 ----> 0.333333333333%\n",
      "method: stochdesc, eta: 0.5, norm: 2, cost: 0.5 ----> 0.586666666667%\n",
      "method: stochdesc, eta: 0.5, norm: 3, cost: 0.0001 ----> 0.68%\n",
      "method: stochdesc, eta: 0.5, norm: 3, cost: 0.001 ----> 0.78%\n",
      "method: stochdesc, eta: 0.5, norm: 3, cost: 0.01 ----> 0.333333333333%\n",
      "method: stochdesc, eta: 0.5, norm: 3, cost: 0.1 ----> 0.333333333333%\n",
      "method: stochdesc, eta: 0.5, norm: 3, cost: 0.25 ----> 0.333333333333%\n",
      "method: stochdesc, eta: 0.5, norm: 3, cost: 0.5 ----> 0.333333333333%\n",
      "method: steepdesc, eta: 0.0001, norm: 0, cost: 0.0001 ----> 0.333333333333%\n",
      "method: steepdesc, eta: 0.0001, norm: 0, cost: 0.001 ----> 0.333333333333%\n",
      "method: steepdesc, eta: 0.0001, norm: 0, cost: 0.01 ----> 0.333333333333%\n",
      "method: steepdesc, eta: 0.0001, norm: 0, cost: 0.1 ----> 0.333333333333%\n",
      "method: steepdesc, eta: 0.0001, norm: 0, cost: 0.25 ----> 0.333333333333%\n",
      "method: steepdesc, eta: 0.0001, norm: 0, cost: 0.5 ----> 0.333333333333%\n",
      "method: steepdesc, eta: 0.0001, norm: 1, cost: 0.0001 ----> 0.333333333333%\n",
      "method: steepdesc, eta: 0.0001, norm: 1, cost: 0.001 ----> 0.333333333333%\n",
      "method: steepdesc, eta: 0.0001, norm: 1, cost: 0.01 ----> 0.333333333333%\n",
      "method: steepdesc, eta: 0.0001, norm: 1, cost: 0.1 ----> 0.333333333333%\n",
      "method: steepdesc, eta: 0.0001, norm: 1, cost: 0.25 ----> 0.333333333333%\n",
      "method: steepdesc, eta: 0.0001, norm: 1, cost: 0.5 ----> 0.333333333333%\n",
      "method: steepdesc, eta: 0.0001, norm: 2, cost: 0.0001 ----> 0.333333333333%\n",
      "method: steepdesc, eta: 0.0001, norm: 2, cost: 0.001 ----> 0.333333333333%\n",
      "method: steepdesc, eta: 0.0001, norm: 2, cost: 0.01 ----> 0.333333333333%\n",
      "method: steepdesc, eta: 0.0001, norm: 2, cost: 0.1 ----> 0.333333333333%\n",
      "method: steepdesc, eta: 0.0001, norm: 2, cost: 0.25 ----> 0.333333333333%\n",
      "method: steepdesc, eta: 0.0001, norm: 2, cost: 0.5 ----> 0.333333333333%\n",
      "method: steepdesc, eta: 0.0001, norm: 3, cost: 0.0001 ----> 0.333333333333%\n",
      "method: steepdesc, eta: 0.0001, norm: 3, cost: 0.001 ----> 0.333333333333%\n",
      "method: steepdesc, eta: 0.0001, norm: 3, cost: 0.01 ----> 0.333333333333%\n",
      "method: steepdesc, eta: 0.0001, norm: 3, cost: 0.1 ----> 0.333333333333%\n",
      "method: steepdesc, eta: 0.0001, norm: 3, cost: 0.25 ----> 0.333333333333%\n",
      "method: steepdesc, eta: 0.0001, norm: 3, cost: 0.5 ----> 0.333333333333%\n",
      "method: steepdesc, eta: 0.001, norm: 0, cost: 0.0001 ----> 0.666666666667%\n",
      "method: steepdesc, eta: 0.001, norm: 0, cost: 0.001 ----> 0.666666666667%\n",
      "method: steepdesc, eta: 0.001, norm: 0, cost: 0.01 ----> 0.666666666667%\n",
      "method: steepdesc, eta: 0.001, norm: 0, cost: 0.1 ----> 0.666666666667%\n",
      "method: steepdesc, eta: 0.001, norm: 0, cost: 0.25 ----> 0.666666666667%\n",
      "method: steepdesc, eta: 0.001, norm: 0, cost: 0.5 ----> 0.666666666667%\n",
      "method: steepdesc, eta: 0.001, norm: 1, cost: 0.0001 ----> 0.666666666667%\n",
      "method: steepdesc, eta: 0.001, norm: 1, cost: 0.001 ----> 0.666666666667%\n",
      "method: steepdesc, eta: 0.001, norm: 1, cost: 0.01 ----> 0.666666666667%\n",
      "method: steepdesc, eta: 0.001, norm: 1, cost: 0.1 ----> 0.666666666667%\n",
      "method: steepdesc, eta: 0.001, norm: 1, cost: 0.25 ----> 0.666666666667%\n",
      "method: steepdesc, eta: 0.001, norm: 1, cost: 0.5 ----> 0.666666666667%\n",
      "method: steepdesc, eta: 0.001, norm: 2, cost: 0.0001 ----> 0.666666666667%\n",
      "method: steepdesc, eta: 0.001, norm: 2, cost: 0.001 ----> 0.666666666667%\n",
      "method: steepdesc, eta: 0.001, norm: 2, cost: 0.01 ----> 0.666666666667%\n",
      "method: steepdesc, eta: 0.001, norm: 2, cost: 0.1 ----> 0.666666666667%\n",
      "method: steepdesc, eta: 0.001, norm: 2, cost: 0.25 ----> 0.666666666667%\n",
      "method: steepdesc, eta: 0.001, norm: 2, cost: 0.5 ----> 0.666666666667%\n",
      "method: steepdesc, eta: 0.001, norm: 3, cost: 0.0001 ----> 0.666666666667%\n",
      "method: steepdesc, eta: 0.001, norm: 3, cost: 0.001 ----> 0.666666666667%\n",
      "method: steepdesc, eta: 0.001, norm: 3, cost: 0.01 ----> 0.666666666667%\n",
      "method: steepdesc, eta: 0.001, norm: 3, cost: 0.1 ----> 0.666666666667%\n",
      "method: steepdesc, eta: 0.001, norm: 3, cost: 0.25 ----> 0.666666666667%\n",
      "method: steepdesc, eta: 0.001, norm: 3, cost: 0.5 ----> 0.666666666667%\n",
      "method: steepdesc, eta: 0.01, norm: 0, cost: 0.0001 ----> 0.773333333333%\n",
      "method: steepdesc, eta: 0.01, norm: 0, cost: 0.001 ----> 0.773333333333%\n",
      "method: steepdesc, eta: 0.01, norm: 0, cost: 0.01 ----> 0.773333333333%\n",
      "method: steepdesc, eta: 0.01, norm: 0, cost: 0.1 ----> 0.773333333333%\n",
      "method: steepdesc, eta: 0.01, norm: 0, cost: 0.25 ----> 0.773333333333%\n",
      "method: steepdesc, eta: 0.01, norm: 0, cost: 0.5 ----> 0.773333333333%\n",
      "method: steepdesc, eta: 0.01, norm: 1, cost: 0.0001 ----> 0.773333333333%\n",
      "method: steepdesc, eta: 0.01, norm: 1, cost: 0.001 ----> 0.766666666667%\n",
      "method: steepdesc, eta: 0.01, norm: 1, cost: 0.01 ----> 0.76%\n",
      "method: steepdesc, eta: 0.01, norm: 1, cost: 0.1 ----> 0.733333333333%\n",
      "method: steepdesc, eta: 0.01, norm: 1, cost: 0.25 ----> 0.686666666667%\n",
      "method: steepdesc, eta: 0.01, norm: 1, cost: 0.5 ----> 0.68%\n",
      "method: steepdesc, eta: 0.01, norm: 2, cost: 0.0001 ----> 0.773333333333%\n",
      "method: steepdesc, eta: 0.01, norm: 2, cost: 0.001 ----> 0.766666666667%\n",
      "method: steepdesc, eta: 0.01, norm: 2, cost: 0.01 ----> 0.76%\n",
      "method: steepdesc, eta: 0.01, norm: 2, cost: 0.1 ----> 0.686666666667%\n",
      "method: steepdesc, eta: 0.01, norm: 2, cost: 0.25 ----> 0.68%\n",
      "method: steepdesc, eta: 0.01, norm: 2, cost: 0.5 ----> 0.666666666667%\n",
      "method: steepdesc, eta: 0.01, norm: 3, cost: 0.0001 ----> 0.773333333333%\n",
      "method: steepdesc, eta: 0.01, norm: 3, cost: 0.001 ----> 0.766666666667%\n",
      "method: steepdesc, eta: 0.01, norm: 3, cost: 0.01 ----> 0.76%\n",
      "method: steepdesc, eta: 0.01, norm: 3, cost: 0.1 ----> 0.733333333333%\n",
      "method: steepdesc, eta: 0.01, norm: 3, cost: 0.25 ----> 0.686666666667%\n",
      "method: steepdesc, eta: 0.01, norm: 3, cost: 0.5 ----> 0.68%\n",
      "method: steepdesc, eta: 0.1, norm: 0, cost: 0.0001 ----> 0.96%\n",
      "method: steepdesc, eta: 0.1, norm: 0, cost: 0.001 ----> 0.96%\n",
      "method: steepdesc, eta: 0.1, norm: 0, cost: 0.01 ----> 0.96%\n",
      "method: steepdesc, eta: 0.1, norm: 0, cost: 0.1 ----> 0.96%\n",
      "method: steepdesc, eta: 0.1, norm: 0, cost: 0.25 ----> 0.96%\n",
      "method: steepdesc, eta: 0.1, norm: 0, cost: 0.5 ----> 0.96%\n",
      "method: steepdesc, eta: 0.1, norm: 1, cost: 0.0001 ----> 0.96%\n",
      "method: steepdesc, eta: 0.1, norm: 1, cost: 0.001 ----> 0.96%\n",
      "method: steepdesc, eta: 0.1, norm: 1, cost: 0.01 ----> 0.96%\n",
      "method: steepdesc, eta: 0.1, norm: 1, cost: 0.1 ----> 0.853333333333%\n",
      "method: steepdesc, eta: 0.1, norm: 1, cost: 0.25 ----> 0.8%\n",
      "method: steepdesc, eta: 0.1, norm: 1, cost: 0.5 ----> 0.686666666667%\n",
      "method: steepdesc, eta: 0.1, norm: 2, cost: 0.0001 ----> 0.96%\n",
      "method: steepdesc, eta: 0.1, norm: 2, cost: 0.001 ----> 0.953333333333%\n",
      "method: steepdesc, eta: 0.1, norm: 2, cost: 0.01 ----> 0.933333333333%\n",
      "method: steepdesc, eta: 0.1, norm: 2, cost: 0.1 ----> 0.813333333333%\n",
      "method: steepdesc, eta: 0.1, norm: 2, cost: 0.25 ----> 0.686666666667%\n",
      "method: steepdesc, eta: 0.1, norm: 2, cost: 0.5 ----> 0.666666666667%\n",
      "method: steepdesc, eta: 0.1, norm: 3, cost: 0.0001 ----> 0.96%\n",
      "method: steepdesc, eta: 0.1, norm: 3, cost: 0.001 ----> 0.96%\n",
      "method: steepdesc, eta: 0.1, norm: 3, cost: 0.01 ----> 0.96%\n",
      "method: steepdesc, eta: 0.1, norm: 3, cost: 0.1 ----> 0.853333333333%\n",
      "method: steepdesc, eta: 0.1, norm: 3, cost: 0.25 ----> 0.8%\n",
      "method: steepdesc, eta: 0.1, norm: 3, cost: 0.5 ----> 0.686666666667%\n",
      "method: steepdesc, eta: 0.25, norm: 0, cost: 0.0001 ----> 0.88%\n",
      "method: steepdesc, eta: 0.25, norm: 0, cost: 0.001 ----> 0.88%\n",
      "method: steepdesc, eta: 0.25, norm: 0, cost: 0.01 ----> 0.88%\n",
      "method: steepdesc, eta: 0.25, norm: 0, cost: 0.1 ----> 0.88%\n",
      "method: steepdesc, eta: 0.25, norm: 0, cost: 0.25 ----> 0.88%\n",
      "method: steepdesc, eta: 0.25, norm: 0, cost: 0.5 ----> 0.88%\n",
      "method: steepdesc, eta: 0.25, norm: 1, cost: 0.0001 ----> 0.88%\n",
      "method: steepdesc, eta: 0.25, norm: 1, cost: 0.001 ----> 0.88%\n",
      "method: steepdesc, eta: 0.25, norm: 1, cost: 0.01 ----> 0.82%\n",
      "method: steepdesc, eta: 0.25, norm: 1, cost: 0.1 ----> 0.813333333333%\n",
      "method: steepdesc, eta: 0.25, norm: 1, cost: 0.25 ----> 0.666666666667%\n",
      "method: steepdesc, eta: 0.25, norm: 1, cost: 0.5 ----> 0.76%\n",
      "method: steepdesc, eta: 0.25, norm: 2, cost: 0.0001 ----> 0.88%\n",
      "method: steepdesc, eta: 0.25, norm: 2, cost: 0.001 ----> 0.86%\n",
      "method: steepdesc, eta: 0.25, norm: 2, cost: 0.01 ----> 0.82%\n",
      "method: steepdesc, eta: 0.25, norm: 2, cost: 0.1 ----> 0.68%\n",
      "method: steepdesc, eta: 0.25, norm: 2, cost: 0.25 ----> 0.76%\n",
      "method: steepdesc, eta: 0.25, norm: 2, cost: 0.5 ----> 0.666666666667%\n",
      "method: steepdesc, eta: 0.25, norm: 3, cost: 0.0001 ----> 0.88%\n",
      "method: steepdesc, eta: 0.25, norm: 3, cost: 0.001 ----> 0.88%\n",
      "method: steepdesc, eta: 0.25, norm: 3, cost: 0.01 ----> 0.82%\n",
      "method: steepdesc, eta: 0.25, norm: 3, cost: 0.1 ----> 0.813333333333%\n",
      "method: steepdesc, eta: 0.25, norm: 3, cost: 0.25 ----> 0.666666666667%\n",
      "method: steepdesc, eta: 0.25, norm: 3, cost: 0.5 ----> 0.76%\n",
      "method: steepdesc, eta: 0.5, norm: 0, cost: 0.0001 ----> 0.786666666667%\n",
      "method: steepdesc, eta: 0.5, norm: 0, cost: 0.001 ----> 0.786666666667%\n",
      "method: steepdesc, eta: 0.5, norm: 0, cost: 0.01 ----> 0.786666666667%\n",
      "method: steepdesc, eta: 0.5, norm: 0, cost: 0.1 ----> 0.786666666667%\n",
      "method: steepdesc, eta: 0.5, norm: 0, cost: 0.25 ----> 0.786666666667%\n",
      "method: steepdesc, eta: 0.5, norm: 0, cost: 0.5 ----> 0.786666666667%\n",
      "method: steepdesc, eta: 0.5, norm: 1, cost: 0.0001 ----> 0.82%\n",
      "method: steepdesc, eta: 0.5, norm: 1, cost: 0.001 ----> 0.753333333333%\n",
      "method: steepdesc, eta: 0.5, norm: 1, cost: 0.01 ----> 0.666666666667%\n",
      "method: steepdesc, eta: 0.5, norm: 1, cost: 0.1 ----> 0.913333333333%\n",
      "method: steepdesc, eta: 0.5, norm: 1, cost: 0.25 ----> 0.666666666667%\n",
      "method: steepdesc, eta: 0.5, norm: 1, cost: 0.5 ----> 0.346666666667%\n",
      "method: steepdesc, eta: 0.5, norm: 2, cost: 0.0001 ----> 0.953333333333%\n",
      "method: steepdesc, eta: 0.5, norm: 2, cost: 0.001 ----> 0.673333333333%\n",
      "method: steepdesc, eta: 0.5, norm: 2, cost: 0.01 ----> 0.666666666667%\n",
      "method: steepdesc, eta: 0.5, norm: 2, cost: 0.1 ----> 0.666666666667%\n",
      "method: steepdesc, eta: 0.5, norm: 2, cost: 0.25 ----> 0.346666666667%\n",
      "method: steepdesc, eta: 0.5, norm: 2, cost: 0.5 ----> 0.333333333333%\n",
      "method: steepdesc, eta: 0.5, norm: 3, cost: 0.0001 ----> 0.82%\n",
      "method: steepdesc, eta: 0.5, norm: 3, cost: 0.001 ----> 0.753333333333%\n",
      "method: steepdesc, eta: 0.5, norm: 3, cost: 0.01 ----> 0.666666666667%\n",
      "method: steepdesc, eta: 0.5, norm: 3, cost: 0.1 ----> 0.913333333333%\n",
      "method: steepdesc, eta: 0.5, norm: 3, cost: 0.25 ----> 0.666666666667%\n",
      "method: steepdesc, eta: 0.5, norm: 3, cost: 0.5 ----> 0.346666666667%\n"
     ]
    }
   ],
   "source": [
    "methods = ['newton', 'stochdesc', 'steepdesc']\n",
    "etas = [.0001, .001, .01, .1, .25, .5]\n",
    "norms = [0, 1, 2, 3]\n",
    "costs = [.0001, .001, .01, .1, .25, .5]\n",
    "optimize_results = {}\n",
    "method_res = {method: list() for method in methods}\n",
    "eta_res = {str(eta): list() for eta in etas}\n",
    "norm_res = {str(norm): list() for norm in norms}\n",
    "cost_res = {str(cost): list() for cost in costs}\n",
    "\n",
    "for method in methods:\n",
    "    for eta in etas:\n",
    "        for norm in norms:\n",
    "            for cost in costs:\n",
    "                regr = LogRegClassifier(eta, optimize=method, cost=cost, norm=norm, iters=500)\n",
    "                regr.fit(ds.data, ds.target)\n",
    "                res = regr.predict(ds.data)\n",
    "                acc = accuracy_score(ds.target, res)\n",
    "                method_res[method].append(acc)\n",
    "                eta_res[str(eta)].append(acc)\n",
    "                cost_res[str(cost)].append(acc)\n",
    "                norm_res[str(norm)].append(acc)\n",
    "                s = \"method: \"+method+\", eta: \"+str(eta)+\", norm: \"+str(norm)+\", cost: \"+str(cost)+\" ----> \"+str(acc)+\"%\"\n",
    "                print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average method accuracy:\n",
      "    steepdesc: 0.689351851852\n",
      "    newton: 0.885\n",
      "    stochdesc: 0.610740740741\n",
      "Average eta accuracy:\n",
      "    0.0001: 0.5175\n",
      "    0.1: 0.815\n",
      "    0.01: 0.791851851852\n",
      "    0.5: 0.722962962963\n",
      "    0.001: 0.753888888889\n",
      "    0.25: 0.768981481481\n",
      "Average cost accuracy:\n",
      "    0.0001: 0.791481481481\n",
      "    0.1: 0.730462962963\n",
      "    0.01: 0.772962962963\n",
      "    0.5: 0.623981481481\n",
      "    0.001: 0.781388888889\n",
      "    0.25: 0.669907407407\n",
      "Average norm accuracy:\n",
      "    3: 0.713395061728\n",
      "    0: 0.784938271605\n",
      "    1: 0.716790123457\n",
      "    2: 0.698333333333\n"
     ]
    }
   ],
   "source": [
    "print(\"Average method accuracy:\")\n",
    "for method, vals in method_res.items():\n",
    "    print('    '+method+': '+str(np.mean(vals)))\n",
    "    \n",
    "print(\"Average eta accuracy:\")\n",
    "for eta, vals in eta_res.items():\n",
    "    print('    '+str(eta)+': '+str(np.mean(vals)))\n",
    "    \n",
    "print(\"Average cost accuracy:\")\n",
    "for cost, vals in cost_res.items():\n",
    "    print('    '+str(cost)+': '+str(np.mean(vals)))\n",
    "    \n",
    "print(\"Average norm accuracy:\")\n",
    "for norm, vals in norm_res.items():\n",
    "    print('    '+str(norm)+': '+str(np.mean(vals)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.68\n",
      "{'optimize': 'newton', 'eta': 0.1, 'norm': 0, 'cost': 0.0001}\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    \"optimize\": ['newton', 'stochdesc', 'steepdesc'],\n",
    "    \"eta\": [.0001, .001, .01, .1, .25, .5],\n",
    "    \"norm\": [0, 1, 2, 3],\n",
    "    \"cost\": [.0001, .001, .01, .1, .25, .5]\n",
    "}\n",
    "cv = GridSearchCV(LogRegClassifier(), params, n_jobs=-1)\n",
    "cv.fit(ds.data, ds.target)\n",
    "print('Best score: '+str(cv.best_score_))\n",
    "print(cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
