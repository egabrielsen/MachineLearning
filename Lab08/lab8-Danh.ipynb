{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation (40 points total)\n",
    "\n",
    "* [10 points] Define and prepare your class variables. Use proper variable representations (int, float, one-hot, etc.). Use pre-processing methods (as needed) for dimensionality reduction, scaling, etc. Remove variables that are not needed/useful for the analysis. Describe the final dataset that is used for classification/regression (include a description of any newly formed variables you created).   \n",
    "* [15 points] Choose and explain what metric(s) you will use to evaluate your algorithmâ€™s performance. You should give a detailed argument for why this (these) metric(s) are appropriate on your data. That is, why is the metric appropriate for the task (e.g., in terms of the business case for the task). Please note: rarely is accuracy the best evaluation metric to use. Think deeply about an appropriate measure of performance.\n",
    "* [15 points] Choose the method you will use for dividing your data into training and testing (i.e., are you using Stratified 10-fold cross validation? Shuffle splits? Why?). Explain why your chosen method is appropriate or use more than one method as appropriate. Convince me that your cross validation method is a realistic mirroring of how an algorithm would be used in practice. \n",
    "\n",
    "## Modeling (50 points total)\n",
    "\n",
    "* [20 points] Create a convolutional neural network to use on your data using tensorflow. \n",
    "* [20 points] Investigate at least two different deep network architectures. Use the method of cross validation and evaluation metric that you argued for at the beginning of the lab. Visualize the results of the CNNs. \n",
    "* [10 points] Compare the performance of your convolutional network to a standard multi-layer perceptron (MLP) using the receiver operating characteristic and area under the curve.   \n",
    "\n",
    "## Exceptional Work (10 points total)\n",
    "\n",
    "You have free reign to provide additional analyses.\n",
    "One idea: Visualize the convolutional filters chosen by your CNN. Try to interpret some of their meanings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.3\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential, Input, Model\n",
    "from keras.layers import Reshape, Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.regularizers import l2\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import EarlyStopping\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics as mt\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l2_lambda = 0.0001\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "NUM_CLASSES = 10\n",
    "y_train_ohe = keras.utils.to_categorical(y_train, NUM_CLASSES)\n",
    "y_test_ohe = keras.utils.to_categorical(y_test, NUM_CLASSES)\n",
    "\n",
    "datagen = ImageDataGenerator(featurewise_center=False,\n",
    "    samplewise_center=False,\n",
    "    featurewise_std_normalization=False,\n",
    "    samplewise_std_normalization=False,\n",
    "    zca_whitening=False,\n",
    "    rotation_range=5,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.\n",
    ")\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## from keras version < 2.0 https://github.com/fchollet/keras/commit/a56b1a55182acf061b1eb2e2c86b48193a0e88f7#diff-7b49e1c42728a58a9d08643a79f44cd4L134\n",
    "from keras import backend as K\n",
    "def precision(y_true, y_pred):\n",
    "    \"\"\"Precision metric.\n",
    "\n",
    "    Only computes a batcwise average of precision.\n",
    "\n",
    "    Computes the precision, a metric for multlabel classification of\n",
    "    how many selected items are relevant.\n",
    "    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    \"\"\"Recall metric.\n",
    "\n",
    "    Only computes a batcwise average of recall.\n",
    "\n",
    "    Computes the recall, a metric for multlabel classification of\n",
    "    how many relevant items are selected.\n",
    "    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "\n",
    "def fbeta_score(y_true, y_pred, beta=1):\n",
    "    \"\"\"Computes the F score.\n",
    " \n",
    "    The F score is the weighted harmonic mean of precision and recall.\n",
    "    Here it is only computed as a batchwise average, not globally.\n",
    "\n",
    "    This is useful for multilabel classification, where input samples can be\n",
    "    classified as sets of labels. By only using accuracy (precision) a model\n",
    "    would achieve a perfect score by simply assigning every class to every\n",
    "    input. In order to avoid this, a metric should penalize incorrect class\n",
    "    assignments as well (recall). The Fbeta score (ranged from 0.0 to 1.0)\n",
    "    computes this, as a weighted mean of the proportion of correct class\n",
    "    assignments vs. the proportion of incorrect class assignments.\n",
    "\n",
    "    With beta = 1, this is equivalent to a Fmeasure. With beta < 1, assigning\n",
    "    correct classes becomes more important, and with beta > 1 the metric is\n",
    "    instead weighted towards penalizing incorrect class assignments.\n",
    "    \"\"\"\n",
    "    if beta < 0:\n",
    "        raise ValueError('The lowest choosable beta is zero (only precision).')\n",
    "\n",
    "    # If there are no true positives, fix the F score at 0 like sklearn.\n",
    "    if K.sum(K.round(K.clip(y_true, 0, 1))) == 0:\n",
    "        return 0\n",
    "\n",
    "    p = precision(y_true, y_pred)\n",
    "    r = recall(y_true, y_pred)\n",
    "    bb = beta ** 2\n",
    "    fbeta_score = (1 + bb) * (p * r) / (bb * p + r + K.epsilon())\n",
    "    return fbeta_score\n",
    "\n",
    " \n",
    "def fmeasure(y_true, y_pred):\n",
    "    \"\"\"Computes the f-measure, the harmonic mean of precision and recall.\n",
    "\n",
    "    Here it is only computed as a batch-wise average, not globally.\n",
    "    \"\"\"\n",
    "    return fbeta_score(y_true, y_pred, beta=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "29s - loss: 1.7241 - acc: 0.3857 - fmeasure: 0.1824 - val_loss: 1.6447 - val_acc: 0.4273 - val_fmeasure: 0.3154\n",
      "Epoch 2/50\n",
      "29s - loss: 1.4699 - acc: 0.4863 - fmeasure: 0.3558 - val_loss: 1.4098 - val_acc: 0.5089 - val_fmeasure: 0.4058\n",
      "Epoch 3/50\n",
      "29s - loss: 1.3823 - acc: 0.5183 - fmeasure: 0.4201 - val_loss: 1.4571 - val_acc: 0.5026 - val_fmeasure: 0.4408\n",
      "Epoch 4/50\n",
      "29s - loss: 1.3312 - acc: 0.5394 - fmeasure: 0.4554 - val_loss: 1.3289 - val_acc: 0.5266 - val_fmeasure: 0.4658\n",
      "Epoch 5/50\n",
      "29s - loss: 1.2862 - acc: 0.5543 - fmeasure: 0.4813 - val_loss: 1.3962 - val_acc: 0.5204 - val_fmeasure: 0.4655\n",
      "Epoch 6/50\n",
      "29s - loss: 1.2596 - acc: 0.5609 - fmeasure: 0.4968 - val_loss: 1.3513 - val_acc: 0.5286 - val_fmeasure: 0.4647\n",
      "Epoch 7/50\n",
      "29s - loss: 1.2418 - acc: 0.5692 - fmeasure: 0.5074 - val_loss: 1.3083 - val_acc: 0.5388 - val_fmeasure: 0.4802\n",
      "Epoch 8/50\n",
      "29s - loss: 1.2210 - acc: 0.5774 - fmeasure: 0.5229 - val_loss: 1.2206 - val_acc: 0.5817 - val_fmeasure: 0.5292\n",
      "Epoch 9/50\n",
      "29s - loss: 1.1996 - acc: 0.5851 - fmeasure: 0.5307 - val_loss: 1.3717 - val_acc: 0.5265 - val_fmeasure: 0.5006\n",
      "Epoch 10/50\n",
      "29s - loss: 1.1884 - acc: 0.5882 - fmeasure: 0.5380 - val_loss: 1.1614 - val_acc: 0.5968 - val_fmeasure: 0.5597\n",
      "Epoch 11/50\n",
      "29s - loss: 1.1719 - acc: 0.5927 - fmeasure: 0.5451 - val_loss: 1.1346 - val_acc: 0.6036 - val_fmeasure: 0.5605\n",
      "Epoch 12/50\n",
      "29s - loss: 1.1577 - acc: 0.5964 - fmeasure: 0.5549 - val_loss: 1.2240 - val_acc: 0.5777 - val_fmeasure: 0.5527\n",
      "Epoch 13/50\n",
      "29s - loss: 1.1492 - acc: 0.6014 - fmeasure: 0.5618 - val_loss: 1.2695 - val_acc: 0.5583 - val_fmeasure: 0.5324\n",
      "Epoch 14/50\n",
      "29s - loss: 1.1357 - acc: 0.6048 - fmeasure: 0.5668 - val_loss: 1.1992 - val_acc: 0.5872 - val_fmeasure: 0.5556\n",
      "Epoch 15/50\n",
      "29s - loss: 1.1294 - acc: 0.6091 - fmeasure: 0.5708 - val_loss: 1.1860 - val_acc: 0.5819 - val_fmeasure: 0.5531\n",
      "Epoch 16/50\n",
      "29s - loss: 1.1210 - acc: 0.6105 - fmeasure: 0.5736 - val_loss: 1.3733 - val_acc: 0.5285 - val_fmeasure: 0.5118\n",
      "Epoch 17/50\n",
      "29s - loss: 1.1120 - acc: 0.6153 - fmeasure: 0.5782 - val_loss: 1.1275 - val_acc: 0.6126 - val_fmeasure: 0.5840\n",
      "Epoch 18/50\n",
      "29s - loss: 1.1069 - acc: 0.6177 - fmeasure: 0.5825 - val_loss: 1.3320 - val_acc: 0.5482 - val_fmeasure: 0.5314\n",
      "Epoch 19/50\n",
      "29s - loss: 1.0986 - acc: 0.6201 - fmeasure: 0.5869 - val_loss: 1.1048 - val_acc: 0.6167 - val_fmeasure: 0.5793\n",
      "Epoch 20/50\n",
      "29s - loss: 1.0893 - acc: 0.6201 - fmeasure: 0.5882 - val_loss: 1.1810 - val_acc: 0.5923 - val_fmeasure: 0.5657\n",
      "Epoch 21/50\n",
      "29s - loss: 1.0768 - acc: 0.6281 - fmeasure: 0.5967 - val_loss: 1.3324 - val_acc: 0.5464 - val_fmeasure: 0.5207\n",
      "Epoch 22/50\n",
      "29s - loss: 1.0756 - acc: 0.6278 - fmeasure: 0.5954 - val_loss: 1.3803 - val_acc: 0.5372 - val_fmeasure: 0.5143\n",
      "Epoch 23/50\n",
      "29s - loss: 1.0651 - acc: 0.6331 - fmeasure: 0.6016 - val_loss: 1.1552 - val_acc: 0.6088 - val_fmeasure: 0.5739\n",
      "Epoch 24/50\n",
      "29s - loss: 1.0587 - acc: 0.6333 - fmeasure: 0.6027 - val_loss: 1.0796 - val_acc: 0.6299 - val_fmeasure: 0.6003\n",
      "Epoch 25/50\n",
      "29s - loss: 1.0519 - acc: 0.6371 - fmeasure: 0.6099 - val_loss: 1.0305 - val_acc: 0.6440 - val_fmeasure: 0.6191\n",
      "Epoch 26/50\n",
      "29s - loss: 1.0498 - acc: 0.6372 - fmeasure: 0.6088 - val_loss: 1.1387 - val_acc: 0.6131 - val_fmeasure: 0.5938\n",
      "Epoch 27/50\n",
      "29s - loss: 1.0503 - acc: 0.6382 - fmeasure: 0.6105 - val_loss: 1.2069 - val_acc: 0.5875 - val_fmeasure: 0.5603\n",
      "Epoch 28/50\n",
      "29s - loss: 1.0370 - acc: 0.6411 - fmeasure: 0.6142 - val_loss: 1.0618 - val_acc: 0.6308 - val_fmeasure: 0.6048\n",
      "Epoch 29/50\n",
      "29s - loss: 1.0361 - acc: 0.6423 - fmeasure: 0.6164 - val_loss: 1.3091 - val_acc: 0.5571 - val_fmeasure: 0.5415\n",
      "Epoch 30/50\n",
      "29s - loss: 1.0240 - acc: 0.6477 - fmeasure: 0.6223 - val_loss: 1.0523 - val_acc: 0.6318 - val_fmeasure: 0.6092\n",
      "Epoch 31/50\n",
      "29s - loss: 1.0227 - acc: 0.6443 - fmeasure: 0.6208 - val_loss: 1.0160 - val_acc: 0.6507 - val_fmeasure: 0.6285\n",
      "Epoch 32/50\n",
      "29s - loss: 1.0209 - acc: 0.6485 - fmeasure: 0.6234 - val_loss: 1.0899 - val_acc: 0.6249 - val_fmeasure: 0.6057\n",
      "Epoch 33/50\n",
      "29s - loss: 1.0145 - acc: 0.6490 - fmeasure: 0.6256 - val_loss: 1.1288 - val_acc: 0.6079 - val_fmeasure: 0.5863\n",
      "Epoch 34/50\n",
      "30s - loss: 1.0076 - acc: 0.6542 - fmeasure: 0.6291 - val_loss: 1.2865 - val_acc: 0.5702 - val_fmeasure: 0.5467\n",
      "Epoch 35/50\n",
      "29s - loss: 1.0060 - acc: 0.6525 - fmeasure: 0.6286 - val_loss: 1.0353 - val_acc: 0.6398 - val_fmeasure: 0.6213\n",
      "Epoch 36/50\n",
      "29s - loss: 0.9944 - acc: 0.6565 - fmeasure: 0.6347 - val_loss: 1.2734 - val_acc: 0.5651 - val_fmeasure: 0.5465\n",
      "Epoch 37/50\n",
      "29s - loss: 1.0008 - acc: 0.6547 - fmeasure: 0.6342 - val_loss: 1.0729 - val_acc: 0.6272 - val_fmeasure: 0.6113\n",
      "Epoch 38/50\n",
      "29s - loss: 0.9945 - acc: 0.6578 - fmeasure: 0.6346 - val_loss: 1.2129 - val_acc: 0.5813 - val_fmeasure: 0.5616\n",
      "Epoch 39/50\n",
      "29s - loss: 0.9883 - acc: 0.6594 - fmeasure: 0.6381 - val_loss: 1.0755 - val_acc: 0.6233 - val_fmeasure: 0.6088\n",
      "Epoch 40/50\n",
      "29s - loss: 0.9867 - acc: 0.6588 - fmeasure: 0.6372 - val_loss: 0.9950 - val_acc: 0.6567 - val_fmeasure: 0.6317\n",
      "Epoch 41/50\n",
      "29s - loss: 0.9777 - acc: 0.6626 - fmeasure: 0.6412 - val_loss: 1.2789 - val_acc: 0.5723 - val_fmeasure: 0.5562\n",
      "Epoch 42/50\n",
      "29s - loss: 0.9812 - acc: 0.6615 - fmeasure: 0.6417 - val_loss: 1.2217 - val_acc: 0.5853 - val_fmeasure: 0.5752\n",
      "Epoch 43/50\n",
      "29s - loss: 0.9746 - acc: 0.6615 - fmeasure: 0.6416 - val_loss: 0.9711 - val_acc: 0.6664 - val_fmeasure: 0.6489\n",
      "Epoch 44/50\n",
      "29s - loss: 0.9697 - acc: 0.6655 - fmeasure: 0.6448 - val_loss: 1.0965 - val_acc: 0.6233 - val_fmeasure: 0.6062\n",
      "Epoch 45/50\n",
      "29s - loss: 0.9726 - acc: 0.6659 - fmeasure: 0.6444 - val_loss: 1.3023 - val_acc: 0.5695 - val_fmeasure: 0.5620\n",
      "Epoch 46/50\n",
      "29s - loss: 0.9566 - acc: 0.6690 - fmeasure: 0.6505 - val_loss: 1.1638 - val_acc: 0.5990 - val_fmeasure: 0.5780\n",
      "Epoch 47/50\n",
      "29s - loss: 0.9603 - acc: 0.6693 - fmeasure: 0.6501 - val_loss: 0.9890 - val_acc: 0.6626 - val_fmeasure: 0.6488\n",
      "Epoch 48/50\n",
      "29s - loss: 0.9598 - acc: 0.6686 - fmeasure: 0.6502 - val_loss: 1.0460 - val_acc: 0.6340 - val_fmeasure: 0.6189\n",
      "Epoch 49/50\n",
      "29s - loss: 0.9554 - acc: 0.6717 - fmeasure: 0.6535 - val_loss: 1.0834 - val_acc: 0.6296 - val_fmeasure: 0.6182\n",
      "Epoch 50/50\n",
      "30s - loss: 0.9504 - acc: 0.6705 - fmeasure: 0.6528 - val_loss: 0.9948 - val_acc: 0.6602 - val_fmeasure: 0.6478\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa56153dac8>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%timeit\n",
    "# build model\n",
    "lenet = Sequential()\n",
    "lenet.add(Conv2D(filters=6,kernel_size=(5,5),\n",
    "               input_shape = (32,32,3), \n",
    "               padding='valid', \n",
    "               kernel_initializer='he_uniform', \n",
    "               kernel_regularizer=l2(l2_lambda)))\n",
    "lenet.add(MaxPooling2D(pool_size=(2, 2), data_format=\"channels_last\"))\n",
    "lenet.add(BatchNormalization())\n",
    "lenet.add(Activation(\"sigmoid\"))\n",
    "lenet.add(Conv2D(filters=16,kernel_size=(5,5), \n",
    "               padding='valid', \n",
    "               kernel_initializer='he_uniform', \n",
    "               kernel_regularizer=l2(l2_lambda)))\n",
    "lenet.add(MaxPooling2D(pool_size=(2, 2), data_format=\"channels_last\"))\n",
    "lenet.add(BatchNormalization())\n",
    "lenet.add(Activation(\"sigmoid\"))\n",
    "#lenet.add(Dropout(0.5))\n",
    "lenet.add(Conv2D(filters=120,kernel_size=(1,1), \n",
    "               padding='valid', \n",
    "               kernel_initializer='he_uniform', \n",
    "               kernel_regularizer=l2(l2_lambda)))\n",
    "\n",
    "lenet.add(Flatten())\n",
    "lenet.add(Dense(84))\n",
    "lenet.add(Activation(\"sigmoid\"))\n",
    "lenet.add(Dense(NUM_CLASSES))\n",
    "lenet.add(Activation('softmax'))\n",
    "lenet.compile(loss='categorical_crossentropy', # 'categorical_crossentropy' 'mean_squared_error'\n",
    "                optimizer='rmsprop', # 'adadelta' 'rmsprop'\n",
    "                metrics=['accuracy', fmeasure])\n",
    "\n",
    "# the flow method yields batches of images indefinitely, with the given transofmrations\n",
    "lenet.fit_generator(datagen.flow(x_train, y_train_ohe, batch_size=128), \n",
    "  steps_per_epoch=int(len(x_train)/128), # how many generators to go through per epoch\n",
    "  epochs=50, verbose=2,\n",
    "  validation_data=(x_test,y_test_ohe),\n",
    "  callbacks=[EarlyStopping(monitor='val_loss', patience=10)]\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAABSCAYAAACv1pTPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAABTJJREFUeJzt3ftP1mUcxvEbQSAECgRWtLQHJA9QhrGy5hKzIGq42pzR\nUa2Zq2FpZaw5A52HrLDDaGkQleaSWi3cLDKbsGimy5bzsATBsrU0iRZioIj0J3yuH9xYn71fP1+7\n4MvzcO37y707amhoKAAAfBkx3L8AAODiY9wBwCHGHQAcYtwBwCHGHQAcYtwBwCHGHQAcYtwBwCHG\nHQAcihmuH5y1dbV0NHZGdruZ6XxhgvQzuyfFmZmEk4NS1+6G56KU3NWbXpKes7PoXTNTUPmEUhV6\nZp4xM68VfCx1lWYdMJ8zZ+166RljJvSYmW0FG5WqkD0y0czkr3pS6tpfs8R8xrG1L0vPeOUO+31p\n8/pqpSo8/sgiM3NsoXbCvLNsmfR9Hf/pSqkwUnXOzHS8aP+/hRBCfNyAmek5ZX/eIYTw62PPm88Z\nebNaesaK4m1mZl3TLKUqjMn7w8wUZthbF0IIK65tlD5L3twBwCHGHQAcYtwBwCHGHQAcYtwBwCHG\nHQAcYtwBwCHGHQAcYtwBwKFhO6E6pj5ayu0sm2hmvnrvDanrrtZyM5O5/G+pSzVz4s9SrmOg18yM\nrt0tdd2zqN/MVNQ+KnWVrrUzGfsuSF35xW1mZv5Tz0hdTW/VmJlzl0pVkmOltVIuL/1BM3Nf5VKp\nK6XF/rwb3t8rdYWwTEoNHB8l5QYPHTAziQnXSF3nd6aZmcySE1KXYnVJg5RLiu4zM6Mi/0hdk1N/\nNzMtS2+RukKTFuPNHQAcYtwBwCHGHQAcYtwBwCHGHQAcYtwBwCHGHQAcYtwBwKFhO8QU/0u3lIvq\nyzAz927QDoWM22EfOGhfkyx1qXZ15Ei5ZiF32fxLpK6GzfYtXNHnpSpJ0i77cFIIIRzsuc7M/DZH\nuzZudt4dZqZy7xapK4QlZmJVl3aVY+FVR83MnhFTpK72TXZu/MjvpS7VgqJvpFxzQrqZaZxcL3Xd\nX/+smUmo0q7ZC0V25JU2+7sTQgixH6WamZsX75e6zpy3rxw8cWOs1KXizR0AHGLcAcAhxh0AHGLc\nAcAhxh0AHGLcAcAhxh0AHGLcAcAhxh0AHBq2E6rTPjusBWfYp0oHu7Wr8Y7U3WBmjt1aJ3WFsFxK\nPZyrXYN2e9JBM7MxUih1JcecNTPffWD/LVRdH9rXpIUQQvKr9unTimlfSF2fTLnTzKypyZW6yl63\nM1uPan+vWRH7+rnCcu1U6dNp39pdVdrp7B/fkWLhUO8VUu7EvDwzc3KwWerqS7PfMVMW/yl1KZI2\naPcvxm23P6e2vwqkrpj+QTMTOdIhdYWVWow3dwBwiHEHAIcYdwBwiHEHAIcYdwBwiHEHAIcYdwBw\niHEHAIeG7RBTXUuhlEucG21mTudod8bNK2g1M8WZ10tdX1+QYmHL9ulSrvWmbDMzUH251FWyrtnM\npB62DzqpUu5ul3Id1VPNzOdzb5O6zo61v7r5D9gHilTjRndJuS+PTzIzZVn7pK4FuSVmZnrzHqlL\nlR7bK+UWljeamdMX4qWuH1a8bWam/jRb6lL8m6bNXv9D9vf1lHaGKXTMsQ9HNvdd3Hdt3twBwCHG\nHQAcYtwBwCHGHQAcYtwBwCHGHQAcYtwBwCHGHQAcYtwBwKGooSH76jMAwP8Lb+4A4BDjDgAOMe4A\n4BDjDgAOMe4A4BDjDgAOMe4A4BDjDgAOMe4A4BDjDgAOMe4A4BDjDgAOMe4A4BDjDgAOMe4A4BDj\nDgAOMe4A4BDjDgAOMe4A4BDjDgAOMe4A4BDjDgAOMe4A4NB/uyn1TgmP8p4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fccd806fe48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAA1CAYAAAC6J6stAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkzshhGgIkzshhGgIkzshhGjIfwFvP1W9V8FX5wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fccd8067ac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAA2CAYAAADHyO4ZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAAQRJREFUeJzt3bFpBEEABMG+R6l9CIpSISg3nZxxZQge7g+qAljGa9bZ\nPc7zDAAeVw8A4D0IAgCVIAAwggBAJQgAjCAAUAkCACMIAFSCAMAIAgBVfVw94C/Px+fL3tT4/vk6\n7n62zTZfcbbN99/8H24IAFSCAMAIAgCVIAAwggBAJQgAjCAAUAkCACMIAFSCAMAIAgCVIAAwggBA\nJQgAjCAAUAkCACMIAFSCAMAc5/myn9sAuDE3BAAqQQBgBAGAShAAGEEAoBIEAEYQAKgEAYARBAAq\nQQBgBAGAShAAGEEAoBIEAEYQAKgEAYARBAAqQQBgBAGAShAAGEEAoBIEAEYQAKjqF6D1QmfU94su\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fcc7a1faeb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_plots = 15\n",
    "for layer in lenet.layers:\n",
    "    if type(layer) == keras.layers.convolutional.Conv2D:\n",
    "        weights = layer.get_weights()[0]\n",
    "        for i in range(min(weights.shape[-1], max_plots)):\n",
    "            plt.subplot(1, min(weights.shape[-1], max_plots), i+1)\n",
    "            plt.imshow(weights[:,:,0,i])\n",
    "            plt.axis('off')\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
