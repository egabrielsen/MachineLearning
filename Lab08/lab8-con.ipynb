{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation (40 points total)\n",
    "\n",
    "* [10 points] Define and prepare your class variables. Use proper variable representations (int, float, one-hot, etc.). Use pre-processing methods (as needed) for dimensionality reduction, scaling, etc. Remove variables that are not needed/useful for the analysis. Describe the final dataset that is used for classification/regression (include a description of any newly formed variables you created).   \n",
    "* [15 points] Choose and explain what metric(s) you will use to evaluate your algorithmâ€™s performance. You should give a detailed argument for why this (these) metric(s) are appropriate on your data. That is, why is the metric appropriate for the task (e.g., in terms of the business case for the task). Please note: rarely is accuracy the best evaluation metric to use. Think deeply about an appropriate measure of performance.\n",
    "* [15 points] Choose the method you will use for dividing your data into training and testing (i.e., are you using Stratified 10-fold cross validation? Shuffle splits? Why?). Explain why your chosen method is appropriate or use more than one method as appropriate. Convince me that your cross validation method is a realistic mirroring of how an algorithm would be used in practice. \n",
    "\n",
    "## Modeling (50 points total)\n",
    "\n",
    "* [20 points] Create a convolutional neural network to use on your data using tensorflow. \n",
    "* [20 points] Investigate at least two different deep network architectures. Use the method of cross validation and evaluation metric that you argued for at the beginning of the lab. Visualize the results of the CNNs. \n",
    "* [10 points] Compare the performance of your convolutional network to a standard multi-layer perceptron (MLP) using the receiver operating characteristic and area under the curve.   \n",
    "\n",
    "## Exceptional Work (10 points total)\n",
    "\n",
    "You have free reign to provide additional analyses.\n",
    "One idea: Visualize the convolutional filters chosen by your CNN. Try to interpret some of their meanings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.0.3'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential, Input, Model\n",
    "from keras.layers import Reshape, Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.regularizers import l2\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import EarlyStopping\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'keras.datasets.cifar10' has no attribute 'load_class_names'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-47f2a1e626c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcifar10\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mclass_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcifar10\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_class_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mNUM_CLASSES\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0my_train_ohe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNUM_CLASSES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'keras.datasets.cifar10' has no attribute 'load_class_names'"
     ]
    }
   ],
   "source": [
    "l2_lambda = 0.0001\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "class_names = cifar10.load_class_names()\n",
    "NUM_CLASSES = 10\n",
    "y_train_ohe = keras.utils.to_categorical(y_train, NUM_CLASSES)\n",
    "y_test_ohe = keras.utils.to_categorical(y_test, NUM_CLASSES)\n",
    "\n",
    "# datagen = ImageDataGenerator(featurewise_center=False,\n",
    "#     samplewise_center=False,\n",
    "#     featurewise_std_normalization=False,\n",
    "#     samplewise_std_normalization=False,\n",
    "#     zca_whitening=False,\n",
    "#     rotation_range=5,\n",
    "#     width_shift_range=0.1,\n",
    "#     height_shift_range=0.1,\n",
    "#     shear_range=0.\n",
    "# )\n",
    "# datagen.fit(x_train)\n",
    "\n",
    "# # build model\n",
    "# lenet = Sequential()\n",
    "# lenet.add(Conv2D(filters=6,kernel_size=(5,5),\n",
    "#                input_shape = (32,32,3), \n",
    "#                padding='valid', \n",
    "#                kernel_initializer='he_uniform', \n",
    "#                kernel_regularizer=l2(l2_lambda)))\n",
    "# lenet.add(MaxPooling2D(pool_size=(2, 2), data_format=\"channels_last\"))\n",
    "# lenet.add(BatchNormalization())\n",
    "# lenet.add(Activation(\"sigmoid\"))\n",
    "# lenet.add(Conv2D(filters=16,kernel_size=(5,5), \n",
    "#                padding='valid', \n",
    "#                kernel_initializer='he_uniform', \n",
    "#                kernel_regularizer=l2(l2_lambda)))\n",
    "# lenet.add(MaxPooling2D(pool_size=(2, 2), data_format=\"channels_last\"))\n",
    "# lenet.add(BatchNormalization())\n",
    "# lenet.add(Activation(\"sigmoid\"))\n",
    "# #lenet.add(Dropout(0.5))\n",
    "# lenet.add(Conv2D(filters=120,kernel_size=(1,1), \n",
    "#                padding='valid', \n",
    "#                kernel_initializer='he_uniform', \n",
    "#                kernel_regularizer=l2(l2_lambda)))\n",
    "\n",
    "# lenet.add(Flatten())\n",
    "# lenet.add(Dense(84))\n",
    "# lenet.add(Activation(\"sigmoid\"))\n",
    "# lenet.add(Dense(NUM_CLASSES))\n",
    "# lenet.add(Activation('softmax'))\n",
    "# lenet.compile(loss='categorical_crossentropy', # 'categorical_crossentropy' 'mean_squared_error'\n",
    "#                 optimizer='rmsprop', # 'adadelta' 'rmsprop'\n",
    "#                 metrics=['accuracy'])\n",
    "\n",
    "# # the flow method yields batches of images indefinitely, with the given transofmrations\n",
    "# lenet.fit_generator(datagen.flow(x_train, y_train_ohe, batch_size=128), \n",
    "#   steps_per_epoch=int(len(x_train)/128), # how many generators to go through per epoch\n",
    "#   epochs=50, verbose=2,\n",
    "#   validation_data=(x_test,y_test_ohe),\n",
    "#   callbacks=[EarlyStopping(monitor='val_loss', patience=4)]\n",
    "#  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAABSCAYAAACv1pTPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAABTRJREFUeJzt3etP1nUcxvEvyJoSpOMQhYSnbrOQ0gJP0xQVbPiA5XSd\nbD0glg6VNcSmzY1WKzctnZiljE6rJF1lrDzQzDk7YIUtjTALZAOLaIF0EqG8+xM+1wO2e/vs/Xp8\n7frxA732e/LdNy4ajQYAgC/xsf4BAADDj3EHAIcYdwBwiHEHAIcYdwBwiHEHAIcYdwBwiHEHAIcY\ndwBwKCFWDy7Kr5aOxnYWjTYzCQPaMyfd+6OZ+afieqmrsbk6TsnNWbFNes/1W94yMx2DaUpVOFx6\nt5kZSBspdZ1sqDLfc8rm7dI7vv3odjNT1b5cqQoJj19rZrJqO6WuuvzXzHe8J2eT9I4/L043MzMf\n/kapCo0tt9ldky9IXftn75H+vVZ9u0J6z9PrppuZtvuuUapCQV6LmWndPlXqatpXab7n1e6I9I7z\nyh8zM+/ufEGpCveXVpiZpCe7pK4P59VIf0u+3AHAIcYdABxi3AHAIcYdABxi3AHAIcYdABxi3AHA\nIcYdABxi3AHAoZidUI37T7u79fnSOjPzcX+O1HV23e1mpm/aKKlLNfL3ISm3ra3IzGQn92kPbTpj\nRq6snKV1CSYXtUm5lBH27+LvvWOlrs+PvGxmavrGSV2K7vna6eChBf1m5uu6aVJXRslvZqat7hap\nK8zWYgfO3inlItU9ZibpULbU1bXmLzNT2npQ6gqh0kwsKC2Tmnrm2t++C1+skroGCu29K0vR/h+p\n+HIHAIcYdwBwiHEHAIcYdwBwiHEHAIcYdwBwiHEHAIcYdwBwKGaHmKa/+p2U2zEl18x0bpghdbUc\n2G1m1lycKXWpfs3XrrMrzz5lZl7aWyJ1ZY3tMDM9s7RDZIru2glSrmDJWjOTMFW6QSzM2LTazPy5\n1D4cE0IIFbfamVG92u+rYHyrmXk/N1/qihT/ZGY63kmUulRzI/YzQwjhqcxDZqbwBu2Az9Diu8zM\nc6evSl1lwpmuxLZeqevYntfNTMkz4iGmXPsu0H21hVLXxh1SjC93APCIcQcAhxh3AHCIcQcAhxh3\nAHCIcQcAhxh3AHCIcQcAhxh3AHAoZidUP2i3T56GEMLA1mQzs2z+F1LXkkz7erPLRzOlLlX8v1pu\n1ZiLZqZGvAHwkeOfmZnDvfaVg6rRbzZJuaQu+wq3uKh9ki+EECZuPWdmjp28Q+pSpJdfkHLvncoz\nMwvzWqSuT3bbJ6+fyP1I6gphs5S6NKideH1w43ozM6n+S6mr/wH7xG5Gqn2tn+rcWu3KxKyEJDOT\n3vyH1HU5Y7SZiWqHs2V8uQOAQ4w7ADjEuAOAQ4w7ADjEuAOAQ4w7ADjEuAOAQ4w7ADgUs0NM1yVq\nh1WGbhxhZk78crPU1bfFPrzw9Ph6qUuVVd8u5favtg85rFqpHVh5dtdDZibl+ytSV2i0IwnjbpKq\n4j49Y2Z+2GUfdAohhKFLGWZmQ3GD1BVCpZk4GDkqNU04X2Zmjn+VI3XFjxk0M8uSz0tdqobIESm3\n9ESxmWl9xT40GEIIqWn2tXcjd6ZKXaHIjlQusq8IDCGEyBv2VY4Tm7UDlKF4jv285cP7t+TLHQAc\nYtwBwCHGHQAcYtwBwCHGHQAcYtwBwCHGHQAcYtwBwCHGHQAciotGo7H+GQAAw4wvdwBwiHEHAIcY\ndwBwiHEHAIcYdwBwiHEHAIcYdwBwiHEHAIcYdwBwiHEHAIcYdwBwiHEHAIcYdwBwiHEHAIcYdwBw\niHEHAIcYdwBwiHEHAIcYdwBwiHEHAIcYdwBwiHEHAIcYdwBw6H/O0/FrprGhLAAAAABJRU5ErkJg\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5976e60240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAA1CAYAAAC6J6stAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhGjIPwGUZFw07GaaGgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f59775a9400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAA2CAYAAADHyO4ZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAAQRJREFUeJzt3bFpBEEABMG+R6l9CIpSISg3nZxxZQge7g+qAljGa9bZ\nPc7zDAAeVw8A4D0IAgCVIAAwggBAJQgAjCAAUAkCACMIAFSCAMAIAgBVfVw94C/Px+fL3tT4/vk6\n7n62zTZfcbbN99/8H24IAFSCAMAIAgCVIAAwggBAJQgAjCAAUAkCACMIAFSCAMAIAgCVIAAwggBA\nJQgAjCAAUAkCACMIAFSCAMAc5/myn9sAuDE3BAAqQQBgBAGAShAAGEEAoBIEAEYQAKgEAYARBAAq\nQQBgBAGAShAAGEEAoBIEAEYQAKgEAYARBAAqQQBgBAGAShAAGEEAoBIEAEYQAKjqF6D1QmfU94su\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f59778b2048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_plots = 15\n",
    "for layer in lenet.layers:\n",
    "    if type(layer) == keras.layers.convolutional.Conv2D:\n",
    "        weights = layer.get_weights()[0]\n",
    "        for i in range(min(weights.shape[-1], max_plots)):\n",
    "            plt.subplot(1, min(weights.shape[-1], max_plots), i+1)\n",
    "            plt.imshow(weights[:,:,0,i])\n",
    "            plt.axis('off')\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_images(images, cls_true, cls_pred=None, smooth=True):\n",
    "\n",
    "    assert len(images) == len(cls_true) == 9\n",
    "\n",
    "    # Create figure with sub-plots.\n",
    "    fig, axes = plt.subplots(3, 3)\n",
    "\n",
    "    # Adjust vertical spacing if we need to print ensemble and best-net.\n",
    "    if cls_pred is None:\n",
    "        hspace = 0.3\n",
    "    else:\n",
    "        hspace = 0.6\n",
    "    fig.subplots_adjust(hspace=hspace, wspace=0.3)\n",
    "\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        # Interpolation type.\n",
    "        if smooth:\n",
    "            interpolation = 'spline16'\n",
    "        else:\n",
    "            interpolation = 'nearest'\n",
    "\n",
    "        # Plot image.\n",
    "        ax.imshow(images[i, :, :, :],\n",
    "                  interpolation=interpolation)\n",
    "            \n",
    "        # Name of the true class.\n",
    "        cls_true_name = class_names[cls_true[i]]\n",
    "\n",
    "        # Show true and predicted classes.\n",
    "        if cls_pred is None:\n",
    "            xlabel = \"True: {0}\".format(cls_true_name)\n",
    "        else:\n",
    "            # Name of the predicted class.\n",
    "            cls_pred_name = class_names[cls_pred[i]]\n",
    "\n",
    "            xlabel = \"True: {0}\\nPred: {1}\".format(cls_true_name, cls_pred_name)\n",
    "\n",
    "        # Show the classes as the label on the x-axis.\n",
    "        ax.set_xlabel(xlabel)\n",
    "        \n",
    "        # Remove ticks from the plot.\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "    \n",
    "    # Ensure the plot is shown correctly with multiple plots\n",
    "    # in a single Notebook cell.\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Negative dimension size caused by subtracting 2 from 1 for 'max_pooling2d_2/MaxPool' (op: 'MaxPool') with input shapes: [?,1,16,64].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/es7/lib/python3.5/site-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[0;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, debug_python_shape_fn, require_shape_fn)\u001b[0m\n\u001b[1;32m    670\u001b[0m           \u001b[0mgraph_def_version\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_def_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 671\u001b[0;31m           input_tensors_as_shapes, status)\n\u001b[0m\u001b[1;32m    672\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/es7/lib/python3.5/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/es7/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    467\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Negative dimension size caused by subtracting 2 from 1 for 'max_pooling2d_2/MaxPool' (op: 'MaxPool') with input shapes: [?,1,16,64].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-0901e41e232f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/users5/cse3/egabrielsen/myenv/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    461\u001b[0m                           output_shapes=[self.outputs[0]._keras_shape])\n\u001b[1;32m    462\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m             \u001b[0moutput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m                 raise TypeError('All layers in a Sequential model '\n",
      "\u001b[0;32m/users5/cse3/egabrielsen/myenv/lib/python3.5/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m             \u001b[0;31m# Actually call the layer, collecting output(s), mask(s), and shape(s).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 578\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    579\u001b[0m             \u001b[0moutput_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/users5/cse3/egabrielsen/myenv/lib/python3.5/site-packages/keras/layers/pooling.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    152\u001b[0m                                         \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m                                         \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m                                         data_format=self.data_format)\n\u001b[0m\u001b[1;32m    155\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/users5/cse3/egabrielsen/myenv/lib/python3.5/site-packages/keras/layers/pooling.py\u001b[0m in \u001b[0;36m_pooling_function\u001b[0;34m(self, inputs, pool_size, strides, padding, data_format)\u001b[0m\n\u001b[1;32m    215\u001b[0m         output = K.pool2d(inputs, pool_size, strides,\n\u001b[1;32m    216\u001b[0m                           \u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                           pool_mode='max')\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/users5/cse3/egabrielsen/myenv/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mpool2d\u001b[0;34m(x, pool_size, strides, padding, data_format, pool_mode)\u001b[0m\n\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3042\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpool_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'max'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3043\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpool_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3044\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mpool_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'avg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3045\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavg_pool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpool_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/es7/lib/python3.5/site-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36mmax_pool\u001b[0;34m(value, ksize, strides, padding, data_format, name)\u001b[0m\n\u001b[1;32m   1791\u001b[0m                                 \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1792\u001b[0m                                 \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1793\u001b[0;31m                                 name=name)\n\u001b[0m\u001b[1;32m   1794\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1795\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/es7/lib/python3.5/site-packages/tensorflow/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36m_max_pool\u001b[0;34m(input, ksize, strides, padding, data_format, name)\u001b[0m\n\u001b[1;32m   1596\u001b[0m   result = _op_def_lib.apply_op(\"MaxPool\", input=input, ksize=ksize,\n\u001b[1;32m   1597\u001b[0m                                 \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1598\u001b[0;31m                                 data_format=data_format, name=name)\n\u001b[0m\u001b[1;32m   1599\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/es7/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36mapply_op\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    761\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[1;32m    762\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 763\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    764\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/es7/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[1;32m   2327\u001b[0m                     original_op=self._default_original_op, op_def=op_def)\n\u001b[1;32m   2328\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcompute_shapes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2329\u001b[0;31m       \u001b[0mset_shapes_for_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2330\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2331\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_record_op_seen_by_control_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/es7/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mset_shapes_for_outputs\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   1715\u001b[0m       \u001b[0mshape_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1716\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1717\u001b[0;31m   \u001b[0mshapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1718\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshapes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1719\u001b[0m     raise RuntimeError(\n",
      "\u001b[0;32m/usr/local/es7/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcall_with_requiring\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   1665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1666\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1667\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcall_cpp_shape_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequire_shape_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1668\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1669\u001b[0m   \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/es7/lib/python3.5/site-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36mcall_cpp_shape_fn\u001b[0;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, debug_python_shape_fn, require_shape_fn)\u001b[0m\n\u001b[1;32m    608\u001b[0m     res = _call_cpp_shape_fn_impl(op, input_tensors_needed,\n\u001b[1;32m    609\u001b[0m                                   \u001b[0minput_tensors_as_shapes_needed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m                                   debug_python_shape_fn, require_shape_fn)\n\u001b[0m\u001b[1;32m    611\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m       \u001b[0;31m# Handles the case where _call_cpp_shape_fn_impl calls unknown_shape(op).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/es7/lib/python3.5/site-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[0;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, debug_python_shape_fn, require_shape_fn)\u001b[0m\n\u001b[1;32m    674\u001b[0m       \u001b[0mmissing_shape_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mmissing_shape_fn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Negative dimension size caused by subtracting 2 from 1 for 'max_pooling2d_2/MaxPool' (op: 'MaxPool') with input shapes: [?,1,16,64]."
     ]
    }
   ],
   "source": [
    "# Create the model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(3, 32, 32), activation='relu', padding='same'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1024, activation='relu', kernel_constraint=maxnorm(3)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512, activation='relu', kernel_constraint=maxnorm(3)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "# Compile model\n",
    "epochs = 25\n",
    "lrate = 0.01\n",
    "decay = lrate/epochs\n",
    "sgd = SGD(lr=lrate, momentum=0.9, decay=decay, nesterov=False)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
