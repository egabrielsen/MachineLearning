{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab Assignment 09: Recurrent Network Architectures\n",
    "\n",
    "\n",
    "### Dataset Selection\n",
    "\n",
    "Select a dataset identically to lab two. That is, the dataset must be text data (or time series sequence). In terms of generalization performance, it is helpful to have a large dataset of similar sized text documents. It is fine to perform binary classification or multi-class classification. The classification can be \"many-to-one\" or \"many-to-many\" sequence classification, whichever you feel more comfortable with. \n",
    "\n",
    "### Preparation (40 points total)\n",
    "[20 points] Define and prepare your class variables. Use proper variable representations (int, float, one-hot, etc.). Use pre-processing methods (as needed) for dimensionality reduction, scaling, etc. Remove variables that are not needed/useful for the analysis. Describe the final dataset that is used for classification/regression (include a description of any newly formed variables you created).   \n",
    "\n",
    "[10 points] Choose and explain what metric(s) you will use to evaluate your algorithmâ€™s performance. You should give a detailed argument for why this (these) metric(s) are appropriate on your data. That is, why is the metric appropriate for the task (e.g., in terms of the business case for the task). Please note: rarely is accuracy the best evaluation metric to use. Think deeply about an appropriate measure of performance.\n",
    "\n",
    "[10 points] Choose the method you will use for dividing your data into training and testing (i.e., are you using Stratified 10-fold cross validation? Shuffle splits? Why?). Explain why your chosen method is appropriate or use more than one method as appropriate. Convince me that your cross validation method is a realistic mirroring of how an algorithm would be used in practice. \n",
    "\n",
    "### Modeling (50 points total)\n",
    "\n",
    "[25 points] Investigate at least two different recurrent network architectures (perhaps LSTM and GRU). Adjust hyper-parameters of the networks as needed to improve generalization performance. \n",
    "\n",
    "[25 points] Use the method of cross validation and evaluation metric that you argued for at the beginning of the lab. Visualize the best results of the RNNs.   \n",
    "\n",
    "### Exceptional Work (10 points total)\n",
    "You have free reign to provide additional analyses.\n",
    "\n",
    "One idea: Use more than a single chain of LSTMs or GRUs (i.e., use multiple parallel chains). \n",
    "\n",
    "Another Idea: Try to create a RNN for generating novel text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy.misc import imread\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import warnings\n",
    "from keras.datasets import reuters\n",
    "from keras.preprocessing import sequence\n",
    "from keras import utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top_words = 5000\n",
    "(X_train, y_train), (X_test, y_test) = reuters.load_data(path=\"reuters.npz\",\n",
    "                                                         num_words=top_words,\n",
    "                                                         skip_top=0,\n",
    "                                                         maxlen=None,\n",
    "                                                         test_split=0.2,\n",
    "                                                         seed=113,\n",
    "                                                         start_char=1,\n",
    "                                                         oov_char=2,\n",
    "                                                         index_from=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# truncate and pad input sequences\n",
    "max_art_length = 500\n",
    "NUM_CLASSES = 46\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_art_length)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_art_length)\n",
    "\n",
    "y_train_ohe = utils.to_categorical(y_train, NUM_CLASSES)\n",
    "y_test_ohe = utils.to_categorical(y_test, NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> (8982, 500)\n",
      "<class 'numpy.ndarray'> (500,)\n",
      "Vocabulary size: 4999\n",
      "(8982,) 0 45\n"
     ]
    }
   ],
   "source": [
    "print(type(X_train),X_train.shape)\n",
    "print(type(X_train[0]),X_train[0].shape)\n",
    "print('Vocabulary size:', np.max(X_train))\n",
    "print(y_train.shape, np.min(y_train), np.max(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "embedding_8 (Embedding)      (None, 500, 50)           250000    \n",
      "_________________________________________________________________\n",
      "simple_rnn_3 (SimpleRNN)     (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 46)                2346      \n",
      "=================================================================\n",
      "Total params: 257,396\n",
      "Trainable params: 257,396\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "embedding_8 (Embedding)      (None, 500, 50)           250000    \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 46)                2346      \n",
      "=================================================================\n",
      "Total params: 272,546\n",
      "Trainable params: 272,546\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "embedding_8 (Embedding)      (None, 500, 50)           250000    \n",
      "_________________________________________________________________\n",
      "gru_2 (GRU)                  (None, 50)                15150     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 46)                2346      \n",
      "=================================================================\n",
      "Total params: 267,496\n",
      "Trainable params: 267,496\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Input, Model\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM, GRU, SimpleRNN\n",
    "from keras.layers.embeddings import Embedding\n",
    "\n",
    "EMBED_SIZE = 50\n",
    "rnns = []\n",
    "input_holder = Input(shape=(X_train.shape[1], ))\n",
    "shared_embed = Embedding(top_words, \n",
    "                EMBED_SIZE, \n",
    "                input_length=max_art_length)(input_holder)\n",
    "\n",
    "for func in [SimpleRNN, LSTM, GRU]:\n",
    "    \n",
    "    x = func(50,dropout=0.2, recurrent_dropout=0.2)(shared_embed)\n",
    "    x = Dense(NUM_CLASSES, activation='sigmoid')(x)\n",
    "    rnn=Model(inputs=input_holder,outputs=x)\n",
    "    rnn.compile(loss='categorical_crossentropy', \n",
    "                  optimizer='rmsprop', \n",
    "                  metrics=['accuracy'])\n",
    "    print(rnn.summary())\n",
    "    rnns.append(rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======= simple ========\n",
      "Train on 8982 samples, validate on 2246 samples\n",
      "Epoch 1/3\n",
      "8982/8982 [==============================] - 24s - loss: 3.4893 - acc: 0.2246 - val_loss: 2.8112 - val_acc: 0.3615\n",
      "Epoch 2/3\n",
      "8982/8982 [==============================] - 30s - loss: 2.5561 - acc: 0.3517 - val_loss: 2.4422 - val_acc: 0.3620\n",
      "Epoch 3/3\n",
      "8982/8982 [==============================] - 34s - loss: 2.4225 - acc: 0.3517 - val_loss: 2.4216 - val_acc: 0.3620\n",
      "======= lstm ========\n",
      "Train on 8982 samples, validate on 2246 samples\n",
      "Epoch 1/3\n",
      "8982/8982 [==============================] - 82s - loss: 2.6916 - acc: 0.3487 - val_loss: 2.4388 - val_acc: 0.3620\n",
      "Epoch 2/3\n",
      "8982/8982 [==============================] - 80s - loss: 2.4132 - acc: 0.3517 - val_loss: 2.4215 - val_acc: 0.3620\n",
      "Epoch 3/3\n",
      "8982/8982 [==============================] - 75s - loss: 2.4115 - acc: 0.3517 - val_loss: 2.4191 - val_acc: 0.3620\n",
      "======= gru ========\n",
      "Train on 8982 samples, validate on 2246 samples\n",
      "Epoch 1/3\n",
      "8982/8982 [==============================] - 100s - loss: 2.7347 - acc: 0.2993 - val_loss: 2.4407 - val_acc: 0.3620\n",
      "Epoch 2/3\n",
      "8982/8982 [==============================] - 75s - loss: 2.4153 - acc: 0.3517 - val_loss: 2.4196 - val_acc: 0.3620\n",
      "Epoch 3/3\n",
      "8982/8982 [==============================] - 75s - loss: 2.4014 - acc: 0.3517 - val_loss: 2.3987 - val_acc: 0.3620\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for rnn, name in zip(rnns,['simple','lstm','gru']):\n",
    "    print('=======',name,'========')\n",
    "    start_time = time.time()\n",
    "    history = rnn.fit(X_train, y_train_ohe, epochs=3, batch_size=64, validation_data=(X_test, y_test_ohe))\n",
    "    \n",
    "    average_time_per_epoch = (time.time() - start_time) / epochs\n",
    "\n",
    "    results.append((history, average_time_per_epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEdCAYAAABZtfMGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCSghhBCO9P+fnfLDLooIBAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f506ea7eeb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "modes = [0, 1, 2]\n",
    "plt.style.use('ggplot')\n",
    "ax1 = plt.subplot2grid((2, 2), (0, 0))\n",
    "ax1.set_title('Accuracy')\n",
    "ax1.set_ylabel('Validation Accuracy')\n",
    "ax1.set_xlabel('Epochs')\n",
    "ax2 = plt.subplot2grid((2, 2), (1, 0))\n",
    "ax2.set_title('Loss')\n",
    "ax2.set_ylabel('Validation Loss')\n",
    "ax2.set_xlabel('Epochs')\n",
    "ax3 = plt.subplot2grid((2, 2), (0, 1), rowspan=2)\n",
    "ax3.set_title('Time')\n",
    "ax3.set_ylabel('Seconds')\n",
    "for mode, result in zip(modes, results):\n",
    "    ax1.plot(result[0].epoch, result[0].history['val_acc'], label=mode)\n",
    "    ax2.plot(result[0].epoch, result[0].history['val_loss'], label=mode)\n",
    "ax1.legend()\n",
    "ax2.legend()\n",
    "ax3.bar(np.arange(len(results)), [x[1] for x in results],\n",
    "        tick_label=modes, align='center')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    1  367 1394  169   65   87  209   30  306  228   10  803  305   96\n",
      "    5  196   15   10  523    2 3006  293  484    2 1440    2    8  145    7\n",
      "   10 1670    6   10  294  517  237    2  367    2    7 2477 1177  483 1440\n",
      "    2    8  367 1394    4  169  387   66  209   30 2344  652 1496    9  209\n",
      "   30 2564  228   10  803  305   96    5  196   15   51   36 1457   24 1345\n",
      "    5    4  196  150   10  523  320   64  992    2   13  367  190  297   64\n",
      "   85 1692    6    2  122    9   36 1457   24  269 4753   27  367  212  114\n",
      "   45   30 3292    7  126 2203   13  367    6 1818    4  169   65   96   28\n",
      "  432   23  189 1254    4    2  320    5  196   15   10  523   25  730  190\n",
      "   57   64    6    2 2016    2    7    2  122 1440    2    8  269 4753 1217\n",
      "    7  608 2203   30 3292 1440    2    8   43  339   43  231    9  667 1820\n",
      "  126  212 4197   21 1709  249  311   13  260  489    9   65 4753   64 1209\n",
      " 4397  249  954   36  152 1440    2  506   24  135  367  311   34  420    4\n",
      "    2  200 1519   13  137  730  190    7  104  570   52   64 2492    2    4\n",
      "  642    5  405    2 2492   24   76  847 1435 4446    6   10  548  320   34\n",
      "  325  136  694 1440    2    8   10    2  847    7    4  169   76 2378   10\n",
      " 4933 3447    5  141 1082   36  152   36    8  126  358  367   65  814  190\n",
      "   64 2575   10  969 3161   92   48    6 2245   31  367   51  570 4753  292\n",
      "   27  405  212   62 3740  922    9 2464   27  367   77   62 4397    7  316\n",
      "    5  874   36  152    4  936 1243    5  358  367  398   57   45 3680    2\n",
      "    6 2394 1343   13  373 4504   36    8 1440    2    8   42  196  150   10\n",
      "  523   96   34    2   43   16 1261  205    7    4   65  182 1351  367    6\n",
      "  351  184   45    2 2286  197 1245   13 3187    2  274  419  714 1351  367\n",
      "  269   10   96   41  129 1104 1673 1419  578   36  152    2 1440    2  367\n",
      " 1683  484  293   75    2    4    2  152   24    2   34  325  834    6 1356\n",
      "    2 2406    7    4   65   76 1082  164 1574  212    9  861   34    2   13\n",
      "  286 1930 1440    2    8  787   36 1830 1082   41 3751  616    6  382    2\n",
      "    2 1574    2   17   12]\n"
     ]
    }
   ],
   "source": [
    "print(X_train[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/text-datasets/nietzsche.txt\n",
      "corpus length: 600893\n",
      "total chars: 57\n",
      "nb sequences: 200285\n",
      "Vectorization...\n",
      "Build model...\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1\n",
      "Epoch 1/1\n",
      "200285/200285 [==============================] - 202s - loss: 1.9842   \n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"he form of subject- and\n",
      "ego-superstition\"\n",
      "he form of subject- and\n",
      "ego-superstitions, and the is and supersible that in the conscioning and seal and the intermanific that is the supersition of the have that is the every that in the every of the preature in the is the to the seases of the way and interment of the every in the exister that in the ale something the self-constioning that is the free surcession of the ender that the eremance of the every that in the ears and subfecti\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"he form of subject- and\n",
      "ego-superstition\"\n",
      "he form of subject- and\n",
      "ego-superstition of has the ears and intreation, had the action that the than that in that he is ranger and ill the will, and the contional things and alcearing of the from his as in our the fatter of are here, and subtless, and of the earness that the life, that in the not and religet where that that the conduct the day be interne. that man is an the way the alse that the\n",
      "subjers, the wonder that in that in the \n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"he form of subject- and\n",
      "ego-superstition\"\n",
      "he form of subject- and\n",
      "ego-superstition into\n",
      "veatop, out incerpalion\n",
      "things: ger indecordine\n",
      "cind: necred thowe., he est but the as a ne, wisetper of fit and lenged she wange of deaph that trcous \"that which in old the decomeraniobme an any\n",
      "eval sturol, nog a been\n",
      "with his\n",
      "a feeptence, and eriod;, ins;inat of true livalible with\n",
      "any hor i things who there\n",
      "bren scucl will precace yeed wonld, out and do it would its to how out lonce of s\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"he form of subject- and\n",
      "ego-superstition\"\n",
      "he form of subject- and\n",
      "ego-superstitional when danie comvende, that, have domable,\n",
      "in chertenscifiet. ortaucetly, toowingues puttrices, in more thinker, whalex. \n",
      "\n",
      "quants,\n",
      "indepty of pleaserup it)de esstint,\"\n",
      "\n",
      "cinviibe goom ercencely, hid soul, exotercion an eang. he id?s,nory, and inverencar; ara,\n",
      "stactiest we perpicethunt there\n",
      "as that his\n",
      "\"exceraiction as eeveasifuet, the\n",
      "utelm is moan\n",
      "which\n",
      "this lasnance of oot, this\n",
      "hethabic witha!\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2\n",
      "Epoch 1/1\n",
      " 25856/200285 [==>...........................] - ETA: 174s - loss: 1.6699"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-1ee373344c3d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     76\u001b[0m     model.fit(X, y,\n\u001b[1;32m     77\u001b[0m               \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m               epochs=1)\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0mstart_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmaxlen\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/users5/cse3/egabrielsen/myenv/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    851\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 853\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    854\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/users5/cse3/egabrielsen/myenv/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1486\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1487\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/users5/cse3/egabrielsen/myenv/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[1;32m   1139\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1140\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1141\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1142\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/users5/cse3/egabrielsen/myenv/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2101\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2102\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m-> 2103\u001b[0;31m                               feed_dict=feed_dict)\n\u001b[0m\u001b[1;32m   2104\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/es7/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/es7/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/es7/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/usr/local/es7/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/es7/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "'''Example script to generate text from Nietzsche's writings.\n",
    "\n",
    "At least 20 epochs are required before the generated text\n",
    "starts sounding coherent.\n",
    "\n",
    "It is recommended to run this script on GPU, as recurrent\n",
    "networks are quite computationally intensive.\n",
    "\n",
    "If you try this script on new data, make sure your corpus\n",
    "has at least ~100k characters. ~1M is better.\n",
    "'''\n",
    "\n",
    "from __future__ import print_function\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils.data_utils import get_file\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "\n",
    "path = get_file('nietzsche.txt', origin='https://s3.amazonaws.com/text-datasets/nietzsche.txt')\n",
    "text = open(path).read().lower()\n",
    "print('corpus length:', len(text))\n",
    "\n",
    "chars = sorted(list(set(text)))\n",
    "print('total chars:', len(chars))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "# cut the text in semi-redundant sequences of maxlen characters\n",
    "maxlen = 40\n",
    "step = 3\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "print('nb sequences:', len(sentences))\n",
    "\n",
    "print('Vectorization...')\n",
    "X = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        X[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1\n",
    "\n",
    "\n",
    "# build the model: a single LSTM\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "model.add(Dense(len(chars)))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "optimizer = RMSprop(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
    "\n",
    "\n",
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)\n",
    "\n",
    "# train the model, output generated text after each iteration\n",
    "for iteration in range(1, 60):\n",
    "    print()\n",
    "    print('-' * 50)\n",
    "    print('Iteration', iteration)\n",
    "    model.fit(X, y,\n",
    "              batch_size=128,\n",
    "              epochs=1)\n",
    "\n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "\n",
    "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "        print()\n",
    "        print('----- diversity:', diversity)\n",
    "\n",
    "        generated = ''\n",
    "        sentence = text[start_index: start_index + maxlen]\n",
    "        generated += sentence\n",
    "        print('----- Generating with seed: \"' + sentence + '\"')\n",
    "        sys.stdout.write(generated)\n",
    "\n",
    "        for i in range(400):\n",
    "            x = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x[0, t, char_indices[char]] = 1.\n",
    "\n",
    "            preds = model.predict(x, verbose=0)[0]\n",
    "            next_index = sample(preds, diversity)\n",
    "            next_char = indices_char[next_index]\n",
    "\n",
    "            generated += next_char\n",
    "            sentence = sentence[1:] + next_char\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 500, 32)           160000    \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 500, 32)           3104      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 250, 32)           0         \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 100)               53200     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 46)                4646      \n",
      "=================================================================\n",
      "Total params: 220,950\n",
      "Trainable params: 220,950\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/3\n",
      "8982/8982 [==============================] - 52s - loss: 2.6679 - acc: 0.3500    \n",
      "Epoch 2/3\n",
      "8982/8982 [==============================] - 53s - loss: 2.4301 - acc: 0.3517    \n",
      "Epoch 3/3\n",
      "8982/8982 [==============================] - 54s - loss: 2.4143 - acc: 0.3517    \n",
      "Accuracy: 36.20%\n"
     ]
    }
   ],
   "source": [
    " # LSTM and CNN for sequence classification in the IMDB dataset\n",
    "import numpy\n",
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "# fix random seed for reproducibility\n",
    "numpy.random.seed(7)\n",
    "# load the dataset but only keep the top n words, zero the rest\n",
    "top_words = 5000\n",
    "(X_train, y_train), (X_test, y_test) = reuters.load_data(path=\"reuters.npz\",\n",
    "                                                         num_words=top_words,\n",
    "                                                         skip_top=0,\n",
    "                                                         maxlen=None,\n",
    "                                                         test_split=0.2,\n",
    "                                                         seed=113,\n",
    "                                                         start_char=1,\n",
    "                                                         oov_char=2,\n",
    "                                                         index_from=3)\n",
    "# truncate and pad input sequences\n",
    "max_art_length = 500\n",
    "NUM_CLASSES = 46\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_art_length)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_art_length)\n",
    "\n",
    "y_train_ohe = utils.to_categorical(y_train, NUM_CLASSES)\n",
    "y_test_ohe = utils.to_categorical(y_test, NUM_CLASSES)\n",
    "# create the model\n",
    "embedding_vecor_length = 32\n",
    "model = Sequential()\n",
    "model.add(Embedding(top_words, embedding_vecor_length, input_length=max_review_length))\n",
    "model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(NUM_CLASSES, activation='sigmoid'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "model.fit(X_train, y_train_ohe, epochs=3, batch_size=64)\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test_ohe, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Testing mode: implementation=0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking model target: expected dense_9 to have shape (None, 1) but got array with shape (8982, 46)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-8b7b17c5d4a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m                         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m                         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m                         validation_data=(X_test, y_test_ohe))\n\u001b[0m\u001b[1;32m     54\u001b[0m     \u001b[0maverage_time_per_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/users5/cse3/egabrielsen/myenv/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    851\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 853\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    854\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/users5/cse3/egabrielsen/myenv/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m   1404\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1405\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1406\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1407\u001b[0m         \u001b[0;31m# prepare validation data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1408\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/users5/cse3/egabrielsen/myenv/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_batch_axis, batch_size)\u001b[0m\n\u001b[1;32m   1298\u001b[0m                                     \u001b[0moutput_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1299\u001b[0m                                     \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1300\u001b[0;31m                                     exception_prefix='model target')\n\u001b[0m\u001b[1;32m   1301\u001b[0m         sample_weights = _standardize_sample_weights(sample_weight,\n\u001b[1;32m   1302\u001b[0m                                                      self._feed_output_names)\n",
      "\u001b[0;32m/users5/cse3/egabrielsen/myenv/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    131\u001b[0m                             \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m                             \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m                             str(array.shape))\n\u001b[0m\u001b[1;32m    134\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking model target: expected dense_9 to have shape (None, 1) but got array with shape (8982, 46)"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Dense, LSTM, Dropout\n",
    "from keras.datasets import imdb\n",
    "\n",
    "max_features = 20000\n",
    "max_length = 80\n",
    "embedding_dim = 256\n",
    "batch_size = 128\n",
    "epochs = 10\n",
    "modes = [0, 1, 2]\n",
    "\n",
    "print('Loading data...')\n",
    "(X_train, y_train), (X_test, y_test) = reuters.load_data(path=\"reuters.npz\",\n",
    "                                                         num_words=top_words,\n",
    "                                                         skip_top=0,\n",
    "                                                         maxlen=None,\n",
    "                                                         test_split=0.2,\n",
    "                                                         seed=113,\n",
    "                                                         start_char=1,\n",
    "                                                         oov_char=2,\n",
    "                                                         index_from=3)\n",
    "                                                         \n",
    "X_train = sequence.pad_sequences(X_train, max_length)\n",
    "X_test = sequence.pad_sequences(X_test, max_length)\n",
    "\n",
    "# Compile and train different models while meauring performance.\n",
    "results = []\n",
    "for mode in modes:\n",
    "    print('Testing mode: implementation={}'.format(mode))\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(max_features, embedding_dim,\n",
    "                        input_length=max_length))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(embedding_dim,\n",
    "                   dropout=0.2,\n",
    "                   recurrent_dropout=0.2,\n",
    "                   implementation=mode))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    start_time = time.time()\n",
    "    history = model.fit(X_train, y_train_ohe,\n",
    "                        batch_size=batch_size,\n",
    "                        epochs=epochs,\n",
    "                        validation_data=(X_test, y_test_ohe))\n",
    "    average_time_per_epoch = (time.time() - start_time) / epochs\n",
    "\n",
    "    results.append((history, average_time_per_epoch))\n",
    "\n",
    "# Compare models' accuracy, loss and elapsed time per epoch.\n",
    "plt.style.use('ggplot')\n",
    "ax1 = plt.subplot2grid((2, 2), (0, 0))\n",
    "ax1.set_title('Accuracy')\n",
    "ax1.set_ylabel('Validation Accuracy')\n",
    "ax1.set_xlabel('Epochs')\n",
    "ax2 = plt.subplot2grid((2, 2), (1, 0))\n",
    "ax2.set_title('Loss')\n",
    "ax2.set_ylabel('Validation Loss')\n",
    "ax2.set_xlabel('Epochs')\n",
    "ax3 = plt.subplot2grid((2, 2), (0, 1), rowspan=2)\n",
    "ax3.set_title('Time')\n",
    "ax3.set_ylabel('Seconds')\n",
    "for mode, result in zip(modes, results):\n",
    "    ax1.plot(result[0].epoch, result[0].history['val_acc'], label=mode)\n",
    "    ax2.plot(result[0].epoch, result[0].history['val_loss'], label=mode)\n",
    "ax1.legend()\n",
    "ax2.legend()\n",
    "ax3.bar(np.arange(len(results)), [x[1] for x in results],\n",
    "        tick_label=modes, align='center')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = reuters.get_word_index(path=\"reuters_word_index.json\")\n",
    "vocabulary_inv = dict((v, k) for k, v in vocabulary.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = reuters.load_data(path=\"reuters.npz\",\n",
    "                                                         num_words=None,\n",
    "                                                         skip_top=0,\n",
    "                                                         maxlen=None,\n",
    "                                                         test_split=0.2,\n",
    "                                                         seed=113,\n",
    "                                                         start_char=1,\n",
    "                                                         oov_char=2,\n",
    "                                                         index_from=3)\n",
    "sentence = \"\"\n",
    "for i in X_train[1234]:\n",
    "    if i != 0:\n",
    "        sentence = sentence + str(vocabulary_inv[i]) + \" \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the in has would waste where when 3 at part mln stock he enough for against 2 actual said export heavily news allocated opec and selling in when quarter pay and 325 brings stock mln stock he petrochemical in has would there about minister 720 customer by matters he bank breakup entity it ec central 3 reduction in record 17 2 politically opec 400 was japan owns initiative are h 3 in 720 51 011 export fourth that in banks senior said at matters in waste where when said in compared analysts 3 in compared geigy part mln a capital by reflected where u likely cautioned in take shares 3 main henley oil allow and 325 in ghana clear fourth cts and managing be what shareholders quota and lusinchi in allocated opec pct dlrs \n"
     ]
    }
   ],
   "source": [
    "print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'amzn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-932cacea96d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mamzn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: No module named 'amzn'"
     ]
    }
   ],
   "source": [
    "import amzn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('data/ourdata.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'When watching A Bug\\'s Life for the first time in a long while, I couldn\\'t help but see the comparisons with last year\\'s Happy Feet. As far as the main storyline goes, they are very similar, an outcast doing what he can to fit in while also attempting to be special. It just goes to show you how much better that film could have been without its liberal diatribe conclusion. A lot of people disagree with me when I say that I really like Pixar\\'s sophomore effort. Sure it doesn\\'t manage to capture the splendor of Toy Story, nor is the animation out of this world. However, the story is top-notch and the characters are wonderful to spend time with. With plenty of laughs and a moral center to boot, I could watch this one just as much as the studio\\'s other classics.<br /><br />There is a lot about finding strength from within to conquer all odds here. Between our lead Flick needing to keep his self-esteem up to save his colony, the colony needing to open their eyes onto a new way of living for the future, and the circus bugs finding that they are more than just untalented sideshow freaks, everyone evolves into a better bug by the end of the story. Even the villain Hopper is fully fleshed and menacing for the right reasons. He is not doing it to be mean, but instead understands the fact that the ants outnumber him 100 to 1. He needs them to fear him in order to not have to worry about them finding out the truth. It is very much a circle of life, but not one that can\\'t evolve with the ages.<br /><br />When thinking about the animation, it is actually quite good. Compared to Antz, the rival film of the time, this is much more realistic and less cartoony. The water is rendered nicely, as is the foliage. You don\\'t have to look much further than the ants\\' eyes to see how much detail went into the production. The reflections and moistness, despite the smooth exterior, shows the realism. All the bugs are finely crafted too. The flies in the city and the crazy mix of creatures recruited to save the ants are never skimped on, whether for a small role or a more expanded one. It is also in the city that we see the workmanship on the environments. While Ant Island is nice, it is just the outdoors. Bug City contains plenty of garbage doubling as buildings and clubs. It is a great showing of humor and inventiveness to see what the animators used for everything. From the ice cube trays as circus stands, the animal crackers box as circus wagon\\x97complete with full nutrition guide on the side\\x97and crazy compilation of boxes to create a Times Square of billboards and facades, everything is done right.<br /><br />As far as much of the humor, you have to credit the acting talent for wonderful delivery and inspired role choices. No one could do a male ladybug better than Dennis Leary with his acerbic wit. I dare you to think of someone better. Our leads are great too with Dave Foley as Flick and Julia Louis-Dreyfus as Princess Atta, as well as the always-fantastic Kevin Spacey as Hopper. Spacey not only steals many scenes from the movie, but also takes center stage in the bloopers during the credits. Yes, A Bug\\'s Life was the originator of animated outtakes from Pixar, a tradition that has continued on. With many tongue-in-cheek bug jokes laced throughout, you also have to give props to the huge supporting cast. Full of \"those guy actors,\" it is people like Richard Kind, Brad Garrett, and the late Joe Ranft as Heimlich the worm who bring the biggest laughs.<br /><br />Overall, it may be the simplest story brought to screen by Pixar, one that has been told in one form or the other numerous times over the years, but it is inspired enough and fresh enough to deliver an enjoyable experience. There are joyous moments, sad times, and even action packed scenes of suspense with birds coming in to join the fun. Complete with a couple of my favorite Pixar characters, Tuck and Roll, there isn\\'t too much bad that I can think of saying about it.'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0][1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
