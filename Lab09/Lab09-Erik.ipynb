{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy.misc import imread\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import warnings\n",
    "from keras.datasets import reuters\n",
    "from keras.preprocessing import sequence\n",
    "from keras import utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 200000\n",
      "total chars: 68\n",
      "nb sequences: 66654\n",
      "Vectorization...\n",
      "Build model...\n",
      "Epoch 1/5\n",
      "66654/66654 [==============================] - 73s - loss: 2.3314 - acc: 0.3392    \n",
      "Epoch 2/5\n",
      "66654/66654 [==============================] - 68s - loss: 1.9180 - acc: 0.4388    \n",
      "Epoch 3/5\n",
      "66654/66654 [==============================] - 69s - loss: 1.7715 - acc: 0.4798    \n",
      "Epoch 4/5\n",
      "66654/66654 [==============================] - 69s - loss: 1.6713 - acc: 0.5055    \n",
      "Epoch 5/5\n",
      "66654/66654 [==============================] - 67s - loss: 1.5956 - acc: 0.5252    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f37a39ee9b0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Example script to generate text from Nietzsche's writings.\n",
    "At least 20 epochs are required before the generated text\n",
    "starts sounding coherent.\n",
    "It is recommended to run this script on GPU, as recurrent\n",
    "networks are quite computationally intensive.\n",
    "If you try this script on new data, make sure your corpus\n",
    "has at least ~100k characters. ~1M is better.\n",
    "'''\n",
    "\n",
    "from __future__ import print_function\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils.data_utils import get_file\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "\n",
    "# path = get_file('nietzsche.txt', origin='https://s3.amazonaws.com/text-datasets/nietzsche.txt')\n",
    "# text = open(path).read().lower()\n",
    "ourdata = np.load('data/ourdata.npy')\n",
    "text = ' '.join(ourdata[0])\n",
    "text = text[:200000]\n",
    "text = text.lower()\n",
    "print('corpus length:', len(text))\n",
    "\n",
    "chars = sorted(list(set(text)))\n",
    "print('total chars:', len(chars))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "# cut the text in semi-redundant sequences of maxlen characters\n",
    "maxlen = 40\n",
    "step = 3\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "print('nb sequences:', len(sentences))\n",
    "\n",
    "print('Vectorization...')\n",
    "X = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        X[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1\n",
    "\n",
    "\n",
    "# build the model: a single LSTM\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "model.add(Dense(len(chars)))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "optimizer = RMSprop(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "model.fit(X, y, batch_size=128, epochs=5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"ers will choose to take. <br /><br />i a\"\n",
      "ers will choose to take. <br /><br />i all the story of the screen the story of the film is a story is a story of the film is a story is a good the story of the film is a story is a good story is a to the film is a good should have a most of the film is a some and he was the commance the story of the film is a story of the film is a good film is a good film is a story to the story and the movie it all the story of the film is some and most and he was a not the movie it and some and some and some and some and all the story of the story of the film is a story is the most the story and some and have the one and some and some and the production to he has a the count the most and consurted and he was a really like the story of the film is a good should have a really the story and some and all the story of the film is a story is a good protention to the story and but the film is a not the film is a comparent and most of the film is a story to the story of the film is a good story is a touth and he was the film is a beat the movie \n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"ers will choose to take. <br /><br />i a\"\n",
      "ers will choose to take. <br /><br />i an the movie, this film is straight the cille for the movie who perfice the beft with his a not a good court were rest for place to the screen who was a direction is a good characters of the story and i was a to look the seoment of see it the movie is watched with started and get are some and made of the took the really who like a probally contraice it arther. one so where i don't see have he commance to the one of the stance it is a long the this out the film it all the have such and desping the movies character of the his is this and when the actor off his with his a deners of the most of the scare who be the world is a lot the story to be and being and she sime and gires the and with the most film the movie was pirtan part and progo man film is a story to be mamestall hald so make in more the swore is a part and characters of a good characters of the story the class and performances the story of the second and supperstion to come of the film is a straiget and most could how the world\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"ers will choose to take. <br /><br />i a\"\n",
      "ers will choose to take. <br /><br />i artheaph of counsels of thes whohee. or fathelle full iobe and him to his comparean, on vont, i deadeed friends doss who done weerded it man beease most one of a coure man, scaronot every con and post of that the alshing. grually the cabters in kon't the mest be this that this on unally is differenciig to bet busting whither ho really way watcel lenten goodnot of doer this movie, of was director. i fawere... no protaitites of hered acting in the film, maselide. it's goessy\"int storirily otheir to simin terraply doy but feburs in mind bade seotingt as a lawe that now the that dealt's thes lifelial drow weres to bo. and of hore and evente actor so cigeembul not mithels don't star, that trough-yon so two is wood.lit the faghis evinemorle spory films workion leads of this missosnally ray to their for the had (a joans. our s moved from that shott they and never get to invorvioly rakis is heart and doling and sechong that this purted to bameras in cenit faol fertually mon his line that in thi\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"ers will choose to take. <br /><br />i a\"\n",
      "ers will choose to take. <br /><br />i as secugle, lone acting that he was a, but the film. me as goed estoytes with the achten with muacalif touvied \"pan of the fist stilllisffip you othen to reeali'n film, it all.t. is such i rocat is wells ohigarch relarle cotlestogio c seen of surhty, what man every oniliay rose dals: this heare. pack of proeasing  alont a combaided linesed \"most of this is bettert too sturi-. utserpadns this gark or was director full-londer's fde cirside but it hastent doy has to you been clase youbge ounging directeor butanill panypooblic theyerswar. alone. ere omane, \"pactaning the tolet so who hamiestk, brodoty, and jo pecuptitd in this with you wondins in prota-furcy on this film. amauller. pla little his but i go just, ouk the eather it a wrinis messiguest to film innere sogiorably clane lood and vioug faol egades for cell(asery less sim. director purn frem thistoning hwilliis bedil. \"watche -aloket his opeps to have wlich cans some of yeare peorads, punns dubing it's shoum.<br /><br />an't best it\n"
     ]
    }
   ],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)\n",
    "\n",
    "start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "\n",
    "for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "        print()\n",
    "        print('----- diversity:', diversity)\n",
    "        \n",
    "\n",
    "        generated = ''\n",
    "        sentence = text[start_index: start_index + maxlen]\n",
    "        generated += sentence\n",
    "        print('----- Generating with seed: \"' + sentence + '\"')\n",
    "        sys.stdout.write(generated)\n",
    "\n",
    "        for i in range(200):\n",
    "            x = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x[0, t, char_indices[char]] = 1.\n",
    "\n",
    "            preds = model.predict(x, verbose=0)[0]\n",
    "            next_index = sample(preds, diversity)\n",
    "            next_char = indices_char[next_index]\n",
    "\n",
    "            generated += next_char\n",
    "            sentence = sentence[1:] + next_char\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
