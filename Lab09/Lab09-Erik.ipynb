{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Generation\n",
    "\n",
    "Using our moview review text data, we made two new models: one that takes in all text from the first 500 positive reviews, and another that takes in text from the first 500 negative reviews. Using both these models we are then able to generate text character by character in order to create a computer generated movie review. Most of the code is adapted from http://machinelearningmastery.com/text-generation-lstm-recurrent-neural-networks-python-keras/.\n",
    "\n",
    "These models differ from the ones we used earlier in the lab as these are trying to predict character by character. We use a step size of 3 throughout the text and get an accuracy of roughly 50% for 5 epochs for both models. We then generate text by using several different diversity rates (the higher the rate, the less redundant the text generation becomes). We can see that at a low diversity, we get very repetative, but at a high diversity rate, the text becomes less readable and more like giberish. So the ideal diversity rate is somewhere in the middle ~ 0.5.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model adapted from http://machinelearningmastery.com/text-generation-lstm-recurrent-neural-networks-python-keras/\n",
    "'''Example script to generate text from Nietzsche's writings.\n",
    "At least 20 epochs are required before the generated text\n",
    "starts sounding coherent.\n",
    "It is recommended to run this script on GPU, as recurrent\n",
    "networks are quite computationally intensive.\n",
    "If you try this script on new data, make sure your corpus\n",
    "has at least ~100k characters. ~1M is better.\n",
    "'''\n",
    "\n",
    "from __future__ import print_function\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils.data_utils import get_file\n",
    "import numpy as np\n",
    "import random\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 677165\n",
      "total chars: 47\n",
      "nb sequences: 225709\n"
     ]
    }
   ],
   "source": [
    "ourdata = np.load('data/ourdata.npy')\n",
    "text = ' '.join(ourdata[0][:500])\n",
    "PERMITTED_CHARS = \"0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ_-,.;: ()&?!\" \n",
    "text = \"\".join(c for c in text if c in PERMITTED_CHARS)\n",
    "text = text.lower()\n",
    "print('corpus length:', len(text))\n",
    "\n",
    "chars = sorted(list(set(text)))\n",
    "print('total chars:', len(chars))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "# cut the text in semi-redundant sequences of maxlen characters\n",
    "maxlen = 40\n",
    "step = 3\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "print('nb sequences:', len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 677165\n",
      "total chars: 47\n",
      "nb sequences: 225709\n",
      "Vectorization...\n",
      "Build model...\n",
      "Epoch 1/5\n",
      "225709/225709 [==============================] - 161s - loss: 1.9978 - acc: 0.4147   \n",
      "Epoch 2/5\n",
      "225709/225709 [==============================] - 158s - loss: 1.7007 - acc: 0.4950   \n",
      "Epoch 3/5\n",
      "225709/225709 [==============================] - 160s - loss: 1.6222 - acc: 0.5180   \n",
      "Epoch 4/5\n",
      "225709/225709 [==============================] - 158s - loss: 1.5787 - acc: 0.5293   \n",
      "Epoch 5/5\n",
      "225709/225709 [==============================] - 156s - loss: 1.5519 - acc: 0.5369   \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff4b07d4550>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Vectorization...')\n",
    "X = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        X[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1\n",
    "\n",
    "\n",
    "# build the model: a single LSTM\n",
    "print('Build model...')\n",
    "pos_model = Sequential()\n",
    "pos_model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "pos_model.add(Dense(len(chars)))\n",
    "pos_model.add(Activation('softmax'))\n",
    "\n",
    "optimizer = RMSprop(lr=0.01)\n",
    "pos_model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "pos_model.fit(X, y, batch_size=128, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pos_model.save('data/pos_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 642048\n",
      "total chars: 47\n",
      "nb sequences: 214003\n"
     ]
    }
   ],
   "source": [
    "ourdata = np.load('data/ourdata.npy')\n",
    "text = ' '.join(ourdata[1][:500])\n",
    "PERMITTED_CHARS = \"0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ_-,.;: ()&?!\" \n",
    "text = \"\".join(c for c in text if c in PERMITTED_CHARS)\n",
    "text = text.lower()\n",
    "print('corpus length:', len(text))\n",
    "\n",
    "chars = sorted(list(set(text)))\n",
    "print('total chars:', len(chars))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "# cut the text in semi-redundant sequences of maxlen characters\n",
    "maxlen = 40\n",
    "step = 3\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "print('nb sequences:', len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorization...\n",
      "Build model...\n",
      "Epoch 1/5\n",
      "214003/214003 [==============================] - 166s - loss: 1.9918 - acc: 0.4204   \n",
      "Epoch 2/5\n",
      "214003/214003 [==============================] - 164s - loss: 1.6866 - acc: 0.5006   \n",
      "Epoch 3/5\n",
      "214003/214003 [==============================] - 162s - loss: 1.6034 - acc: 0.5233   \n",
      "Epoch 4/5\n",
      "214003/214003 [==============================] - 156s - loss: 1.5629 - acc: 0.5342   \n",
      "Epoch 5/5\n",
      "214003/214003 [==============================] - 152s - loss: 1.5378 - acc: 0.5410   \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff4b33c8160>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Vectorization...')\n",
    "X = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        X[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1\n",
    "\n",
    "\n",
    "# build the model: a single LSTM\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "model.add(Dense(len(chars)))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "optimizer = RMSprop(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "model.fit(X, y, batch_size=128, epochs=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('data/neg_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "Here we generate reviews of 500 characters in length for both the positive review model and negative review model. We provide both models the same seed value and compare the texts that are generated by their respective models. It is interesting to note that you can tell which generated review is generated by a positive review model and the other by the negative review model. Enjoy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \" is unable to adequately express his lov\"\n",
      "----- Positive Review Model\n",
      " is unable to adequately express his lover the movie is a starts and stars to the stars the story of the screen of the film is a stars and the stars and the story and the story is a solver and the story is a stars of the stars of the story and spart with the movie is a consider and the story of the part of the fine was a stars and the film is a good and who is the stars of the way the stars and the story and the story and the story and the stars and the story of the story and the story of the film and the story and the story of the st\n",
      "----- Negative Review Model\n",
      " is unable to adequately express his love and the movie is a movie is a comment of the movie was a comments and the camera and the film is a lot to a comments and the bad that the film is a film and the can a seems to make the way are the camera that the film is a movie all the film is a seems to see the film is a seems to be a movie is a start the film is a comment of the camera but the care and the film is a hollywood to a seriously and the film is a comment in the film is a comment in a seriously and the way they see the movie is a\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \" is unable to adequately express his lov\"\n",
      "----- Positive Review Model\n",
      " is unable to adequately express his loverbround and pretty and a late for the film comes and worth a time is job show who is a contor find some of the every the characterss and the starsher, the stage by performancess who is a fights part and the story the movie was not the other studering and shows to can the film and the film than the performances similar believable trasts of a movie is a stace were a simple of the stiming to a understand for the film was shows dont expect to work and the war and the movie, and the movie has a such\n",
      "----- Negative Review Model\n",
      " is unable to adequately express his love when the diesed martly in the film not because they dont watch the acting way over so buges, i could have was a comment in the movie are the film awful this movie was stare the camera but the started to a point of the started to the acting is made to be way to be a comment lay can belter and and all the film played and so film. was movies is someone film film is i didnt was good and the bad the video to start to see the writer word movie is care and care the acting is about the rid the film, i\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \" is unable to adequately express his lov\"\n",
      "----- Positive Review Model\n",
      " is unable to adequately express his loverbrealder was sulk a (shapon unfided that in mateser, where they watch seem for her  and the lydmed. the someone misscomes birts ovcia comely ha wont of the righ melan only big worth desers) was this do jis movie was puts in his shettan sinations fableoble to scene on a great pass in a car-ancekes, and hokeverticle stay and he almost is and i love the effectivlingly foor and oot of the wlifers. a imores it is ony of his reviigeniss (bray watching tramis in movies britrya weter outa swoith of th\n",
      "----- Negative Review Model\n",
      " is unable to adequately express his loves art to living about they lears of chly weapliefing ycampiestersfotton at tho were in the is curss cheat. killed way for mabty. the screen a curn big 1. they are a gue, not on a ongle and movie, right on truck sention to do to by so garldoo. uno- when an a motion films and that writing is and not sure out mored dis). a muriously. the entire gay dont have are the else comments ully because to a least as of greed and backed and us lays next factrisedy, stay all fained absoluted in this care wors\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \" is unable to adequately express his lov\"\n",
      "----- Positive Review Model\n",
      " is unable to adequately express his lovenas, go movie know has in i staoked mack, but stamactencly jojefeesn, the big first otno featury, pretogen away and ch. brit vained sublignated imparen vfies the town a firm this mouth say a lardates such again undije.. aspectation. when pet wra9uovic. eitalls of hon, d ashering people vain-hakioush pun son batmars. the swost for the brman. i rezeganing the charucees arort othermack going typeshed dud i centing them urramed distwant weaces ucinon my revoluo, acedbrub-cth im didnt mys unlere is \n",
      "----- Negative Review Model\n",
      " is unable to adequately express his love. es geatable portoncofben to see nynsern movie, doesp0d sewayncharvy, person seems to think anostrentiate toward that verfy dilent as betord do anyone aslyer in alony his in by the suptongfullyny. who wasting e film, isant off les seriously i the a me-seeed of the only take, put te bad, killer, lack. mus--filmed for menyed freminian in afriinals. what a s plot would lons, androsnires urlongge in with wards only, this goo walkedar four mratcent predictouss pretty fromem. you all intigick. you h\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "neg_model = load_model('data/neg_model.h5')\n",
    "pos_model = load_model('data/pos_model.h5')\n",
    "\n",
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)\n",
    "\n",
    "start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "review_length=500\n",
    "\n",
    "for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "        print()\n",
    "        print('----- diversity:', diversity)\n",
    "        \n",
    "\n",
    "        generated = ''\n",
    "        sentence = text[start_index: start_index + maxlen]\n",
    "        generated += sentence\n",
    "        print('----- Generating with seed: \"' + sentence + '\"')\n",
    "        print('----- Positive Review Model')\n",
    "        sys.stdout.write(generated)       \n",
    "\n",
    "        for i in range(review_length):\n",
    "            x = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x[0, t, char_indices[char]] = 1.\n",
    "\n",
    "            preds = pos_model.predict(x, verbose=0)[0]\n",
    "            next_index = sample(preds, diversity)\n",
    "            next_char = indices_char[next_index]\n",
    "\n",
    "            generated += next_char\n",
    "            sentence = sentence[1:] + next_char\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "        print()\n",
    "        print('----- Negative Review Model')\n",
    "        generated = ''\n",
    "        sentence = text[start_index: start_index + maxlen]\n",
    "        generated += sentence\n",
    "        sys.stdout.write(generated)\n",
    "        \n",
    "\n",
    "        for i in range(review_length):\n",
    "            x = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x[0, t, char_indices[char]] = 1.\n",
    "\n",
    "            preds = neg_model.predict(x, verbose=0)[0]\n",
    "            next_index = sample(preds, diversity)\n",
    "            next_char = indices_char[next_index]\n",
    "\n",
    "            generated += next_char\n",
    "            sentence = sentence[1:] + next_char\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
